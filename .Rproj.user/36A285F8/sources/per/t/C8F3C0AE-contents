#' Reads DLC Tracking data from a csv file and returns a TrackingData object
#' 
#' @param file path to a DLC tracking .csv file
#' @param fps frames per second of the recording. required to enable time resolved metrics
#' @return An object of type TrackingData
#' @examples
#' ReadDLCDataFromCSV("DLCData/Data.csv", fps = 25)
ReadDLCDataFromCSV <- function(file,fps = 1){
  out <- list()
  out$data <- list()
  data.header <- read.table(file, sep =",", header = T, nrows = 1)
  data.header <- data.frame(sapply(data.header, as.character), stringsAsFactors=FALSE)
  raw.data <- read.table(file, sep =",", header = T, skip = 2)
  for(i in seq(from = 2, to = nrow(data.header), by = 3)){
    out$data[[paste(data.header[i,])]] <- data.frame(frame = raw.data$coords, x = raw.data[,i], y = raw.data[,(i+1)], likelihood = raw.data[,(i+2)])
  }
  
  
  if(fps == 1){
    warning("no fps set. setting fps to 1. keep in mind that time based analyses are resolved in frames / second")
  }
  out$frames <- raw.data$coords
  out$fps <- fps
  out$seconds <- out$frames / fps
  
  out$median.data <- NULL
  for(i in names(out$data)){
    out$median.data <- rbind(out$median.data, data.frame(PointName = i, x = median(out$data[[i]]$x), y = median(out$data[[i]]$y)))
  }
  rownames(out$median.data) <- out$median.data$PointName
  
  out$point.info <- data.frame(PointName = names(out$data), PointType = "NotDefined")
  out$distance.units <- "pixel"
  out$labels <- list()
  out$filename <- last(strsplit(file,split = "/")[[1]])
  out$object.type = "TrackingData"
  
  return(out)
}

#' Adds a dataframe with point info to the tracking data and checks its validity
#' 
#' @param t an object of type TrackingData
#' @param pointinfo A data frame with additional point info. Requires variables: 'PointName' and `PointTyp'
#' @return An object of type TrackingData
#' @examples
#' AddPointInfo(Data, PointInfoDataFrame)
#' AddPointInfo(Data, data.frame(PointName = c("nose","tail","top","bottom), PointTyp = c("Mouse","Mouse","Maze","Maze)))
AddPointInfo <- function(t,pointinfo){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  out <- t
  if(is.null(pointinfo$PointName)){
    warning("point info does not contain required variable PointName. could not add point info")
    return(t)
  }
  if(is.null(pointinfo$PointType)){
    warning("point info does not contain required variable PointType could not add point info")
    return(t)
  }
  
  if(length(setdiff(names(t$data),pointinfo$PointName)) != 0){
    warning(paste("point info missing for following points:", setdiff(names(t$data),pointinfo$PointName), " "))
  }
  out$point.info <- pointinfo
  
  return(out)
}

#' Checks if object is of type TrackingData
#' 
#' @param t an object of type TrackingData
#' @return a boolean
#' @examples
#' IsTrackingData(Tracking)
IsTrackingData <- function(t){
  if(!is.null(t$object.type)){
    if(t$object.type == "TrackingData"){
      return(TRUE)
    }
  }
  return(FALSE)
}

#' Cuts an object of type TrackingData into a shorter object of the same type
#' 
#' @param start if not null the first start frames will be removed
#' @param end if not null the last end frames will be removed
#' @param keep.frames a numeric vector. if not null, frames that intersect with this vector will be kept
#' @param remove.frames a numeric vector. if not null, frames that intersect with this vector will be removed
#' @return An object of type TrackingData
#' @examples
#' CutTrackingData(Data, start = 100, end = 100)
#' CutTrackingData(Data, keep.frames = c(10,11,12,13))
#' CutTrackingData(Data, remove.frames = c(21,22,23,24))
CutTrackingData <- function(t,start = NULL, end = NULL, remove.frames = NULL, keep.frames = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  keep <- t$frames
  if(!is.null(start)){
    keep <- keep[-(1:start)]
  }
  if(!is.null(end)){
    keep <- keep[-((length(keep) - end):length(keep))]
  }
  if(!is.null(remove.frames)){
    keep <- setdiff(keep, remove.frames)
  }
  if(!is.null(keep.frames)){
    keep <- intersect(keep, keep.frames)
  }
  t$frames <- keep
  if(!is.null(t$seconds)){
    t$seconds <- t$seconds[keep+1]
  }
  if(length(names(t$labels)) > 0){
    for(i in (names(t$labels))){
      t$labels[[i]] <- t$labels[[i]][keep+1]
    }
  }
  if(!is.null(t$features)){
    t$features <- t$features[keep + 1,]
  }
  
  for(i in 1:length(t$data)){
    t$data[[i]] <- t$data[[i]][t$data[[i]]$frame %in% keep,]
  }
  return(t)
}

#' Cleanes up an object of type Tracking data. missing data is replaced by data interpolation
#' 
#' @param t an object of type TrackingData
#' @param likelihoodcutoff points below this likelihoodcutoff from DLC will be interpolated
#' @param existence.pol points outside of the polygon existence.pol will be interpolated
#' @param maxdelta points that move more than maxdelta in one frame (cm or px, depending on calibrated data or not) will be interpolated
#' @return An object of type TrackingData
#' @examples
#' CleanTrackingData(t)
#' CleanTrackingData(t, likelihoodcutoff = 0.9)
#' CleanTrackingData(t, existence.pol = data.frame(x = c(0,100,100,0), y = c(100,100,0,0)))
#' CleanTrackingData(t, likelihoodcutoff = 1, maxdelta = 5)
CleanTrackingData <- function(t, likelihoodcutoff = 0.95, existence.pol = NULL, maxdelta = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  print(paste("interpolating points with likelihood < ", likelihoodcutoff, sep = ""))
  if(!is.null(existence.pol)){
    print("interpolating points which are outside of the existence area")
  }
  if(!is.null(maxdelta)){
    print(paste("interpolating points with a maximum delta of", maxdelta, t$distance.units,"per frame", sep = " "))
  }
  
  for(i in 1:length(t$data)){
    process <- t$data[[i]]$likelihood < likelihoodcutoff
    if(!is.null(existence.pol)){
      if(is.null(existence.pol$x) | is.null(existence.pol$y)){
        warning("warning. existence.pol is invalid. polygon data needs to include variable x and variable")
      }else if(length(existence.pol$x) != length(existence.pol$y)){
        warning("invalid polygon entered. polygon data needs to include variable x and variable y of equal length")
      }else{
        process <- process | !point.in.polygon(t$data[[i]]$x,t$data[[i]]$y,existence.pol$x, existence.pol$y)
      }
    }
    if(!is.null(maxdelta)){
      process <- process | (sqrt(integratevector(t$data[[i]]$x) ^2 + integratevector(t$data[[i]]$y)^2) > maxdelta)
    }
    t$data[[i]]$x[process] <- NA
    t$data[[i]]$y[process] <- NA
    t$data[[i]] <- na_interpolation(t$data[[i]])
  }
  return(t)
}

#' Calibrates an object of type TrackingData from pixel to metric space
#' 
#' @param t an object of type TrackingData to be calibrated
#' @param method use "distance" or "area". distance requires 2 points, area a polygon with > 2 points
#' @param in.metric the measured distance or area in metric units
#' @param points a vector of tracked points that are used for calibration
#' @return An object of type TrackingData
#' @examples
#' CalibrateTrackingData(t, method = "distance", in.metric = 40, points = c("top","bottom"))
#' CalibrateTrackingData(t, method = "area", in.metric = 1600, points = c("top.left","top.right","bottom.right","bottom.left"))
CalibrateTrackingData <- function(t, method, in.metric = NULL, points = NULL, ratio = NULL, new.units = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(!method %in% c("distance","area","ratio")){
    warning("invalid method: valid methods are distance, area or ratio, can not calibrate")
    return(t)
  }
  if(method == "ratio"){
    if(is.numeric(ratio)){
      t$px.to.cm <- ratio
    }else{
      warning("method ratio needs a valid ratio to be entered. can not calibrate")
      return(t)
    }
  }else{
    if(is.numeric(in.metric) & is.null(points)){
      warning("method requires both points and a in.metric (numeric!) measurement")
      return(t)
    }
    if(sum(!(points %in% t$median.data$PointName))){
      warning("invalid points entered, can not calibrate")
      return(t)
    }
    
    if(method == "distance"){
      if(length(points) == 2){
        t$px.to.cm <- in.metric / Distance2d(t$median.data[points[1],],t$median.data[points[2],]) 
      }else{
        warning("invalid number of points: distance needs 2 points, can not calibrate")
        return(t)
      }
    }
    if(method == "area"){
      if(length(points) > 2){
        t$px.to.cm <- sqrt(in.metric / AreaPolygon2d(t$median.data[points,])) 
      }else{
        warning("invalid number of points: area need polygon of > 2 points, can not calibrate")
        return(t)
      }
    }
  }
  
  for(i in 1:length(t$data)){
    t$data[[i]]$x <- t$data[[i]]$x * t$px.to.cm
    t$data[[i]]$y <- t$data[[i]]$y * t$px.to.cm
  }
  if(!is.null(t$median.data)){
    t$median.data[,c("x","y")] <- t$median.data[,c("x","y")] * t$px.to.cm
  }
  if(!is.null(t$zones)){
    for(i in 1:length(t$zones)){
      t$zones[[i]]$x <- t$zones[[i]]$x * t$px.to.cm
      t$zones[[i]]$y <- t$zones[[i]]$y * t$px.to.cm
    }
  }
  if(!is.null(new.units)){
    t$distance.units <- new.units
  }else{
    t$distance.units <- "cm"
  }
  
  return(t)
} 

#' Scales a polygon by a factor
#' 
#' @param p a polygon (type list() or data.frame() with elements x and y are required)
#' @param factor scaling facor
#' @return a polygon
#' @examples
#' ScalePolygon(p = data.frame(x = c(0,0,1,1), y = c(0,1,1,0)), factor = 1.3)
ScalePolygon <-function(p, factor){
  if(is.null(p$x) | is.null(p$y)){
    stop("invalid input. Needs polygon of type list() or data.frame() with 2 variables, x = and y =")
  }
  center_x <- mean(p$x)
  center_y <- mean(p$y)
  return(data.frame(x = center_x + factor * (p$x - center_x), y = center_y + factor * (p$y - center_y)))
}

#' Recenters a polygon to a new center point
#' 
#' @param p a polygon (type list() or data.frame() with elements x and y are required)
#' @param new_center the new center point (type list() or data.frame() with elements x and y are required)
#' @return a polygon
#' @examples
#' RecenterPolygon(p = data.frame(x = c(0,0,1,1), y = c(0,1,1,0)), new_center = data.frame(x=1,y=1))
RecenterPolygon <-function(p, new_center){
  center_x <- mean(p$x)
  center_y <- mean(p$y)
  return(data.frame(x = p$x + new_center$x - center_x , y = p$y + new_center$y - center_y))
}

#' Adds Zones required for OFT analysis to an object of type TrackingData
#' 
#' @param t an object of type TrackingData
#' @param points a vector of point names describing the corners of the arena (!THE ORDER IS IMPORTANT)
#' @param scale_center a factor by which the arena is scaled to define the center
#' @param scale_periphery a factor by which the arena is scaled to define the periphery
#' @param scale_corners a factor by which the arena is scaled before recentering to each corner
#' @return a polygon
#' @examples
#' AddOFTZones(t, c("tl","tr","br","bl"), 0.5,0.4,0.8)
AddOFTZones <- function(t, points = c("tl","tr","br","bl"), scale_center = 0.5, scale_corners = 0.4, scale_periphery = 0.8){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(intersect(points,names(t$data) != 4))){
    warning("invalid number or type of points entered. exactly 4 existing points needed for OFT Zones")
    return(t)
  }
  zones <- list()
  zones.invert <- list()
  zones[["arena"]] <- t$median.data[points,c("x","y")]
  zones.invert[["arena"]] <- FALSE
  zones[["center"]] <- ScalePolygon(t$median.data[points,c("x","y")], scale_center)
  zones.invert[["center"]] <- FALSE
  zones[["periphery"]] <- ScalePolygon(t$median.data[points,c("x","y")], scale_periphery)
  zones.invert[["periphery"]] <- TRUE
  t$corner.names <- NULL
  for(i in points){
    zones[[paste("corner",i, sep = ".")]] <- RecenterPolygon(ScalePolygon(t$median.data[points,c("x","y")], scale_corners), t$median.data[i,c("x","y")])
    zones.invert[[paste("corner",i, sep = ".")]] <- FALSE
    t$corner.names <- append(t$corner.names,paste("corner",i, sep = "."))
  }
  t$zones <- zones
  t$zones.invert <- zones.invert
  return(t)
}

#' Performs an OFT analysis on an object of type TrackingData
#' 
#' @param t an object of type TrackingData
#' @param movement_cutoff a numeric value that denotes the cutoff point above which an animal is considered moving
#' @param integration_period a numeric value that denotes the duration over which metrics are smoothed.
#' @param points a string or vector of strings that denotes the name of points which will be analysed
#' @return a TrackingData object
#' @examples
#' OFTAnalysis(t, movement_cutoff = 5,integration_period = 5,points = "bodycentre")
OFTAnalysis <- function(t, movement_cutoff,integration_period, points){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    warning("no zones defined for OFT analysis. Returing simple analysis only")
  }
  
  t <- CalculateMovement(t,movement_cutoff,integration_period)
  
  t$Report <- list()
  if(!is.null(t$labels)){
    t$Report <- append(t$Report,LabelReport(t, integration_period))
  }
  
  for(k in points){
    dat <- t$data[[k]]
    t$Report[[paste(k, "raw.distance", sep = ".")]] <- sum(dat[,"speed"], na.rm = T)
    t$Report[[paste(k, "distance.moving", sep = ".")]] <- sum(dat[dat$is.moving,"speed"], na.rm = T)
    t$Report[[paste(k, "raw.speed", sep = ".")]] <- mean(dat[,"speed"], na.rm = T) * t$fps
    t$Report[[paste(k, "speed.moving", sep = ".")]] <- mean(dat[dat$is.moving,"speed"], na.rm = T) * t$fps
    t$Report[[paste(k, "time.moving", sep = ".")]] <- sum(dat[,"is.moving"], na.rm = T) / t$fps
    t$Report[[paste(k, "total.time", sep = ".")]] <- length(dat[,"is.moving"]) / t$fps
    t$Report[[paste(k, "time.stationary", sep = ".")]] <- t$Report[[paste(k, "total.time", sep = ".")]] - t$Report[[paste(k, "time.moving", sep = ".")]]
    t$Report[[paste(k, "percentage.moving", sep = ".")]] <- t$Report[[paste(k, "time.moving", sep = ".")]] / t$Report[[paste(k, "total.time", sep = ".")]] * 100
    
    if(!is.null(t$zones)){
      t$Report <- append(t$Report, ZoneReport(t,k,"center", zone.name = paste(k,"center", sep = ".")))
      t$Report <- append(t$Report, ZoneReport(t,k,"periphery" , zone.name = paste(k,"periphery", sep = "."), invert = TRUE))
      t$Report <- append(t$Report, ZoneReport(t,k,t$corner.names, zone.name = paste(k,"corners", sep = ".")))
    }
  }
  return(t)
}

#' Performs an EPM analysis on an object of type TrackingData
#' 
#' @param t an object of type TrackingData
#' @param movement_cutoff a numeric value that denotes the cutoff point above which an animal is considered moving
#' @param integration_period a numeric value that denotes the duration over which metrics are smoothed.
#' @param points a string or vector of strings that denotes the name of points which will be analysed
#' @return a TrackingData object
#' @examples
#' EPMAnalysis(t, 5,5,"bodycentre")
EPMAnalysis <- function(t, movement_cutoff,integration_period, points,nosedips = FALSE){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    warning("no zones defined for EPM analysis. Returing simple analysis only")
  }
  
  t <- CalculateMovement(t, movement_cutoff,integration_period)
  t$Report <- list()
  
  #THIS IS A VERA ARBITRARY SECTION FOR THIS TYPE OF ANALYSIS. IT WILL ONLY WORK WITH THE CORRECT POINTS AND ZONES
  if(nosedips){
    if((length(setdiff(c("headcentre","bodycentre","neck"),names(t$data))) != 0) | (length(setdiff(c("closed.top","closed.bottom","arena"),names(t$zones))) != 0)){
      warning("Not all points or zones needed for nosedip analysis. Requires points : headcentre,bodycentre,neck and zones closed.top, closed.bottom, arena")
    }else{
      t$labels$automatic.nosedip <- avgbool(!IsInZone(t,"headcentre","arena") & IsInZone(t,"bodycentre","arena") &!IsInZone(t,"neck",c("closed.top","closed.bottom")),integration_period)
      t$Report[["nose.dip"]] <- CalculateTransitions(t$labels$automatic.nosedip,integration_period) / 2
      t$labels$automatic.nosedip <- ifelse(t$labels$automatic.nosedip == 1,"Nosedip","None")
    }
  }
  
  for(k in points){
    dat <- t$data[[k]]
    t$Report[[paste(k, "raw.distance", sep = ".")]] <- sum(dat[,"speed"], na.rm = T)
    t$Report[[paste(k, "distance.moving", sep = ".")]] <- sum(dat[dat$is.moving,"speed"], na.rm = T)
    t$Report[[paste(k, "raw.speed", sep = ".")]] <- mean(dat[,"speed"], na.rm = T) * t$fps
    t$Report[[paste(k, "speed.moving", sep = ".")]] <- mean(dat[dat$is.moving,"speed"], na.rm = T) * t$fps
    t$Report[[paste(k, "time.moving", sep = ".")]] <- sum(dat[,"is.moving"], na.rm = T) / t$fps
    t$Report[[paste(k, "total.time", sep = ".")]] <- length(dat[,"is.moving"]) / t$fps
    t$Report[[paste(k, "time.stationary", sep = ".")]] <- t$Report[[paste(k, "total.time", sep = ".")]] - t$Report[[paste(k, "time.moving", sep = ".")]]
    t$Report[[paste(k, "percentage.moving", sep = ".")]] <- t$Report[[paste(k, "time.moving", sep = ".")]] / t$Report[[paste(k, "total.time", sep = ".")]] * 100
    
    t$Report <- append(t$Report, ZoneReport(t,k,"center", zone.name = paste(k,"center", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,c("open.right","open.left"), zone.name = paste(k,"open", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,c("closed.top","closed.bottom"), zone.name = paste(k,"closed", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,"closed.top",  zone.name = paste(k,"closed.top", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,"closed.bottom",  zone.name = paste(k,"closed.bottom", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,"open.left", zone.name = paste(k,"open.left", sep = ".")))
    t$Report <- append(t$Report, ZoneReport(t,k,"open.right", zone.name = paste(k,"open.right", sep = ".")))
  }
  return(t)
}

#' Checks if point p is in zone(s) z
#' 
#' @param t an object of type TrackingData
#' @param p string value of a point
#' @param z a string or vector of strings naming the zones to be checked
#' @param invert if TRUE instead it will be checked if the point is outside the zone
#' @return a boolean vector for the assessment at each frame
#' @examples
#' IsInZone(t, "bodycentre","center")
IsInZone <- function(t,p,z,invert = FALSE){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(intersect(p,names(t$data))) != 1){
    warning(paste("Points not available in Tracking data:",paste(setdiff(points, names(t$data)),collapse = " "), sep = " "))
    return(NULL)
  }
  if(length(intersect(z,names(t$zones))) != length(z)){
    warning(paste("Zones in Tracking data:",paste(setdiff(z, names(t$zones)),collapse = " "), sep = " "))
    return(NULL)
  }
  
  
  zones <- t$zones[z]
  in.zone <- rep(FALSE,nrow(t$data[[p]]))
  for(i in zones){
    in.zone <- in.zone | (point.in.polygon(t$data[[p]]$x,t$data[[p]]$y,i$x,i$y) == 1)
  }
  if(invert){
    in.zone <- !in.zone
  }
  return(in.zone)
}

#' Creates a report for each behavior which includes total time of behavior and number of onset/offsets
#' 
#' @param t an object of type TrackingData
#' @param integration_period string value of a point
#' @return a list of metrics for each behavior
#' @examples
#' ClassificationReport(t, integration_period = 5)
LabelReport <- function(t, integration_period = 0){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(t$labels) == 0){
    warning("no label data present")
    return(NULL)
  }
  Report <- list()
  for(j in names(t$labels)){
    c <- SmoothLabel(t$labels[[j]],integration_period)
    c <- na.omit(c)
    for(i in unique(c)){
      Report[[paste(j,i,"time", sep = ".")]] <- sum(c == i) / t$fps
      Report[[paste(j,i,"count", sep = ".")]] <- sum(CalculateTransitions(c == i, 0)) / 2
    }
  }
  return(Report)
}

CalculateMovement <- function(t, movement_cutoff, integration_period){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  for(i in 1:length(t$data)){
    t$data[[i]]$delta_x <- integratevector(t$data[[i]]$x)
    t$data[[i]]$delta_y <- integratevector(t$data[[i]]$y)
    t$data[[i]]$speed <- sqrt(t$data[[i]]$delta_x ^2 + t$data[[i]]$delta_y^2)
    t$data[[i]]$acceleration <- integratevector(t$data[[i]]$speed)
    t$data[[i]]$is.moving <- as.logical(avgbool(t$data[[i]]$speed > (movement_cutoff / t$fps), integration_period))
  }
  t$integration_period <- integration_period
  return(t)
}

CalculateAccelerations <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  for(i in 1:length(t$data)){
    t$data[[i]]$delta_x <- integratevector(t$data[[i]]$x)
    t$data[[i]]$delta_y <- integratevector(t$data[[i]]$y)
    t$data[[i]]$speed <- sqrt(t$data[[i]]$delta_x ^2 + t$data[[i]]$delta_y^2)
    t$data[[i]]$acceleration <- integratevector(t$data[[i]]$speed)
  }
  return(t)
}

ZoneReport <- function(t,point,zones, zone.name = NULL, invert = FALSE){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  Report <- list()
  if(is.null(zone.name)){
    zone.name <- paste(zones, collapse = ".")
  }
  if(!point %in% names(t$data)){
    warning("Invalid point")
    return(NULL)
  }
  if(!sum(zones %in% names(t$zones))){
    warning("Invalid zone(s)")
    return(NULL)
  }
  
  dat <- t$data[[point]]
  in.zone <- rep(FALSE,nrow(dat))
  for(i in t$zones[zones]){
    in.zone <- in.zone | (point.in.polygon(dat$x,dat$y,i$x,i$y) == 1)
  }
  if(invert){
    in.zone <- !in.zone
  }
  Report[[paste(zone.name, "raw.distance", sep = ".")]] <- sum(dat[in.zone,"speed"], na.rm = T)
  Report[[paste(zone.name, "distance.moving", sep = ".")]] <- sum(dat[dat$is.moving & in.zone,"speed"], na.rm = T)
  Report[[paste(zone.name, "raw.speed", sep = ".")]] <- mean(dat[in.zone,"speed"], na.rm = T) * t$fps
  Report[[paste(zone.name, "speed.moving", sep = ".")]] <- mean(dat[dat$is.moving & in.zone,"speed"], na.rm = T) * t$fps
  Report[[paste(zone.name, "time.moving", sep = ".")]] <- sum(dat[in.zone,"is.moving"], na.rm = T) / t$fps
  Report[[paste(zone.name, "total.time", sep = ".")]] <- length(dat[in.zone,"is.moving"]) / t$fps
  Report[[paste(zone.name, "time.stationary", sep = ".")]] <- Report[[paste(zone.name, "total.time", sep = ".")]] - Report[[paste(zone.name, "time.moving", sep = ".")]]
  Report[[paste(zone.name, "percentage.moving", sep = ".")]] <- Report[[paste(zone.name, "time.moving", sep = ".")]] / Report[[paste(zone.name, "total.time", sep = ".")]] * 100
  Report[[paste(zone.name, "transitions", sep = ".")]] <- CalculateTransitions(in.zone, t$integration_period) 
  
  return(Report)
}

Distance2d <- function(a,b){
  sqrt((a$x - b$x)^2 + (a$y - b$y)^2)
}

MedianMouseArea <- function(t,points = c("nose","earr","bcr","hipr","tailbase","hipl","bcl","earl")){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  median(GetPolygonAreas(t,points), na.rm = T)
}

MedianMouseLength <- function(t, front  = "nose", back = "tailbase"){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  median(GetDistances(t,front,back), na.rm = T)
}

AreaPolygon2d <- function(p){
  area <- 0
  for(i in 1:nrow(p)){
    if(i != nrow(p)){
      area <- area + p$x[i]*p$y[i+1] - p$y[i]*p$x[i+1]
    }else{
      area <- area + p$x[i]*p$y[1] - p$y[i]*p$x[1]
    }
  }
  return(abs(area/2))
}

GetPolygonAreas <-function(t,points){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(intersect(points,names(t$data))) != length(unique(points))){
    warning(paste("Points for distance measurement not available in Tracking data:",paste(setdiff(points, names(t$data)),collapse = " "), sep = " "))
    return(NULL)
  }
  x <- NULL
  y <- NULL
  for(i in points){
    x <- cbind(x,t$data[[i]]$x )
    y <- cbind(y,t$data[[i]]$y )
  }
  AreaPolygon3d(x,y)
}

GetDistances <- function(t,f,b){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(intersect(c(f,b),names(t$data))) != 2){
    warning(paste("Points for distance measurement not available in Tracking data:",paste(setdiff(c(f,b), names(t$data)),collapse = " "), sep = " "))
  }
  Distance2d(t$data[[f]],t$data[[b]])
}

AreaPolygon3d <- function(x,y){
  area <- 0
  for(i in 1:dim(x)[2]){
    if(i != dim(x)[2]){
      area <- area + x[,i]*y[,i+1] - y[,i]*x[,i+1]
    }else{
      area <- area + x[,i]*y[,1] - y[,i]*x[,1]
    }
  }
  return(abs(area/2))
}

AddLabelingData <- function(t, lab){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  t$labels$manual <- rep("None",length(t$seconds))
  for(i in 1:nrow(lab)){
    t$labels$manual[t$seconds >= lab[i,"from"] & t$seconds <= lab[i,"to"]] <- as.character(lab[i,"type"])
  }
  return(t)
}

CreateSkeletonData <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(S1 = GetDistances(t,"nose","headcentre"))
  dat$S2 <- GetDistances(t,"headcentre","neck")
  dat$S3 <- GetDistances(t,"neck","bodycentre")
  dat$S4 <- GetDistances(t,"bodycentre","bcr")
  dat$S5 <- GetDistances(t,"bodycentre","bcl")
  dat$S6 <- GetDistances(t,"bodycentre","tailbase")
  dat$S7 <- GetDistances(t,"tailbase","hipr")
  dat$S8 <- GetDistances(t,"tailbase","hipl")
  dat$S9 <- GetDistances(t,"tailbase","tailcentre")
  dat$S10 <- GetDistances(t,"tailcentre","tailtip")
  dat$A1 <- GetAngleTotal(t,"tailbase","tailcentre","tailcentre","tailtip")
  dat$A2 <- GetAngleTotal(t,"hipr","tailbase","tailbase","hipl")
  dat$A3 <- GetAngleTotal(t,"tailbase","bodycentre","bodycentre","neck")
  dat$A4 <- GetAngleTotal(t,"bcr","bodycentre","bodycentre","bcl")
  dat$A5 <- GetAngleTotal(t,"bodycentre","neck","neck","headcentre")
  dat$A6 <- GetAngleTotal(t,"tailbase","bodycentre","neck","headcentre")
  dat$Ar1 <- GetPolygonAreas(t,c("tailbase","hipr","hipl"))
  dat$Ar2 <- GetPolygonAreas(t,c("hipr","hipl","bcl","bcr"))
  dat$Ar3 <- GetPolygonAreas(t,c("bcr","earr","earl","bcl"))
  dat$Ar4 <- GetPolygonAreas(t,c("earr","nose","earl"))
  dat <- as.data.frame(dat) 
  t$features <- dat
  return(t)
}

CreateSkeletonData_OFT <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(S1 = GetDistances(t,"nose","headcentre"))
  dat$S2 <- GetDistances(t,"headcentre","neck")
  dat$S3 <- GetDistances(t,"neck","bodycentre")
  dat$S4 <- GetDistances(t,"bodycentre","bcr")
  dat$S5 <- GetDistances(t,"bodycentre","bcl")
  dat$S6 <- GetDistances(t,"bodycentre","tailbase")
  dat$S7 <- GetDistances(t,"tailbase","hipr")
  dat$S8 <- GetDistances(t,"tailbase","hipl")
  dat$S9 <- GetDistances(t,"tailbase","tailcentre")
  dat$S10 <- GetDistances(t,"tailcentre","tailtip")
  dat$A1 <- GetAngleTotal(t,"tailbase","tailcentre","tailcentre","tailtip")
  dat$A2 <- GetAngleTotal(t,"hipr","tailbase","tailbase","hipl")
  dat$A3 <- GetAngleTotal(t,"tailbase","bodycentre","bodycentre","neck")
  dat$A4 <- GetAngleTotal(t,"bcr","bodycentre","bodycentre","bcl")
  dat$A5 <- GetAngleTotal(t,"bodycentre","neck","neck","headcentre")
  dat$A6 <- GetAngleTotal(t,"tailbase","bodycentre","neck","headcentre")
  dat$Ar1 <- GetPolygonAreas(t,c("tailbase","hipr","hipl"))
  dat$Ar2 <- GetPolygonAreas(t,c("hipr","hipl","bcl","bcr"))
  dat$Ar3 <- GetPolygonAreas(t,c("bcr","earr","earl","bcl"))
  dat$Ar4 <- GetPolygonAreas(t,c("earr","nose","earl"))
  dat$P1 <- as.integer(IsInZone(t,"nose","arena"))
  dat$P2 <- as.integer(IsInZone(t,"headcentre","arena"))
  dat <- as.data.frame(dat) 
  t$features <- dat
  
  return(t)
}

CreateSkeletonData_OFT_v2 <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(Ac1 = t$data[["nose"]]$acceleration)
  dat$Ac2 <- t$data[["headcentre"]]$acceleration
  dat$Ac3 <- t$data[["neck"]]$acceleration
  dat$Ac4 <- t$data[["earr"]]$acceleration
  dat$Ac5 <- t$data[["earl"]]$acceleration
  dat$Ac6 <- t$data[["bodycentre"]]$acceleration
  dat$Ac7 <- t$data[["bcl"]]$acceleration
  dat$Ac8 <- t$data[["bcr"]]$acceleration
  dat$Ac9 <- t$data[["hipl"]]$acceleration
  dat$Ac10 <- t$data[["hipr"]]$acceleration
  dat$Ac11 <- t$data[["tailbase"]]$acceleration
  dat$S1 <- GetDistances(t,"nose","headcentre")
  dat$S2 <- GetDistances(t,"headcentre","neck")
  dat$S3 <- GetDistances(t,"neck","bodycentre")
  dat$S4 <- GetDistances(t,"bodycentre","bcr")
  dat$S5 <- GetDistances(t,"bodycentre","bcl")
  dat$S6 <- GetDistances(t,"bodycentre","tailbase")
  dat$S7 <- GetDistances(t,"tailbase","hipr")
  dat$S8 <- GetDistances(t,"tailbase","hipl")
  dat$S9 <- GetDistances(t,"tailbase","tailcentre")
  dat$S10 <- GetDistances(t,"tailcentre","tailtip")
  dat$A1 <- GetAngleTotal(t,"tailbase","tailcentre","tailcentre","tailtip")
  dat$A2 <- GetAngleTotal(t,"hipr","tailbase","tailbase","hipl")
  dat$A3 <- GetAngleTotal(t,"tailbase","bodycentre","bodycentre","neck")
  dat$A4 <- GetAngleTotal(t,"bcr","bodycentre","bodycentre","bcl")
  dat$A5 <- GetAngleTotal(t,"bodycentre","neck","neck","headcentre")
  dat$A6 <- GetAngleTotal(t,"tailbase","bodycentre","neck","headcentre")
  dat$Ar1 <- GetPolygonAreas(t,c("tailbase","hipr","hipl"))
  dat$Ar2 <- GetPolygonAreas(t,c("hipr","hipl","bcl","bcr"))
  dat$Ar3 <- GetPolygonAreas(t,c("bcr","earr","earl","bcl"))
  dat$Ar4 <- GetPolygonAreas(t,c("earr","nose","earl"))
  dat$P1 <- as.integer(IsInZone(t,"nose","arena"))
  dat$P2 <- as.integer(IsInZone(t,"headcentre","arena"))
  dat <- as.data.frame(dat) 
  t$features <- dat
  
  return(t)
}

CreateSkeletonData_OFT_v3 <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(Ac1 = t$data[["nose"]]$acceleration)
  dat$Ac2 <- t$data[["headcentre"]]$acceleration
  dat$Ac3 <- t$data[["neck"]]$acceleration
  dat$Ac4 <- t$data[["earr"]]$acceleration
  dat$Ac5 <- t$data[["earl"]]$acceleration
  dat$Ac6 <- t$data[["bodycentre"]]$acceleration
  dat$Ac7 <- t$data[["bcl"]]$acceleration
  dat$Ac8 <- t$data[["bcr"]]$acceleration
  dat$Ac9 <- t$data[["hipl"]]$acceleration
  dat$Ac10 <- t$data[["hipr"]]$acceleration
  dat$Ac11 <- t$data[["tailbase"]]$acceleration
  dat$S1 <- GetDistances(t,"nose","headcentre")
  dat$S2 <- GetDistances(t,"headcentre","neck")
  dat$S3 <- GetDistances(t,"neck","bodycentre")
  dat$S4 <- GetDistances(t,"bodycentre","bcr")
  dat$S5 <- GetDistances(t,"bodycentre","bcl")
  dat$S6 <- GetDistances(t,"bodycentre","tailbase")
  dat$S7 <- GetDistances(t,"tailbase","hipr")
  dat$S8 <- GetDistances(t,"tailbase","hipl")
  dat$S9 <- GetDistances(t,"tailbase","tailcentre")
  dat$S10 <- GetDistances(t,"tailcentre","tailtip")
  dat$A1 <- GetAngleTotal(t,"tailbase","tailcentre","tailcentre","tailtip")
  dat$A2 <- GetAngleTotal(t,"hipr","tailbase","tailbase","hipl")
  dat$A3 <- GetAngleTotal(t,"tailbase","bodycentre","bodycentre","neck")
  dat$A4 <- GetAngleTotal(t,"bcr","bodycentre","bodycentre","bcl")
  dat$A5 <- GetAngleTotal(t,"bodycentre","neck","neck","headcentre")
  dat$A6 <- GetAngleTotal(t,"tailbase","bodycentre","neck","headcentre")
  dat$Ar1 <- GetPolygonAreas(t,c("tailbase","hipr","hipl"))
  dat$Ar2 <- GetPolygonAreas(t,c("hipr","hipl","bcl","bcr"))
  dat$Ar3 <- GetPolygonAreas(t,c("bcr","earr","earl","bcl"))
  dat$Ar4 <- GetPolygonAreas(t,c("earr","nose","earl"))
  dat$D1 <- GetDistanceToZoneBorder(t,"arena","nose")
  dat$D2 <- GetDistanceToZoneBorder(t,"arena","neck")
  dat$D3 <- GetDistanceToZoneBorder(t,"arena","bodycentre")
  dat$D4 <- GetDistanceToZoneBorder(t,"arena","tailbase")
  dat <- as.data.frame(dat) 
  t$features <- dat
  
  return(t)
}

CreateSkeletonData_FST_v2 <- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(Ac1 = t$data[["nose"]]$acceleration)
  dat$Ac2 <- t$data[["headcentre"]]$acceleration
  dat$Ac3 <- t$data[["neck"]]$acceleration
  dat$Ac4 <- t$data[["earr"]]$acceleration
  dat$Ac5 <- t$data[["earl"]]$acceleration
  dat$Ac6 <- t$data[["bodycentre"]]$acceleration
  dat$Ac7 <- t$data[["bcl"]]$acceleration
  dat$Ac8 <- t$data[["bcr"]]$acceleration
  dat$Ac9 <- t$data[["hipl"]]$acceleration
  dat$Ac10 <- t$data[["hipr"]]$acceleration
  dat$Ac11 <- t$data[["tailbase"]]$acceleration
  dat$S1 <- GetDistances(t,"nose","headcentre")
  dat$S2 <- GetDistances(t,"headcentre","neck")
  dat$S3 <- GetDistances(t,"neck","bodycentre")
  dat$S4 <- GetDistances(t,"bodycentre","bcr")
  dat$S5 <- GetDistances(t,"bodycentre","bcl")
  dat$S6 <- GetDistances(t,"bodycentre","tailbase")
  dat$S7 <- GetDistances(t,"tailbase","hipr")
  dat$S8 <- GetDistances(t,"tailbase","hipl")
  dat$S9 <- GetDistances(t,"tailbase","tailcentre")
  dat$S10 <- GetDistances(t,"tailcentre","tailtip")
  dat$A1 <- GetAngleTotal(t,"tailbase","tailcentre","tailcentre","tailtip")
  dat$A2 <- GetAngleTotal(t,"hipr","tailbase","tailbase","hipl")
  dat$A3 <- GetAngleTotal(t,"tailbase","bodycentre","bodycentre","neck")
  dat$A4 <- GetAngleTotal(t,"bcr","bodycentre","bodycentre","bcl")
  dat$A5 <- GetAngleTotal(t,"bodycentre","neck","neck","headcentre")
  dat$A6 <- GetAngleTotal(t,"tailbase","bodycentre","neck","headcentre")
  dat$Ar1 <- GetPolygonAreas(t,c("tailbase","hipr","hipl"))
  dat$Ar2 <- GetPolygonAreas(t,c("hipr","hipl","bcl","bcr"))
  dat$Ar3 <- GetPolygonAreas(t,c("bcr","earr","earl","bcl"))
  dat$Ar4 <- GetPolygonAreas(t,c("earr","nose","earl"))
  dat <- as.data.frame(dat) 
  t$features <- abs(dat)
  
  return(t)
}

CreateAccelerationFeatures<- function(t){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- data.frame(Ac1 = t$data[["nose"]]$acceleration)
  dat$Ac2 <- t$data[["headcentre"]]$acceleration
  dat$Ac3 <- t$data[["neck"]]$acceleration
  dat$Ac4 <- t$data[["earr"]]$acceleration
  dat$Ac5 <- t$data[["earl"]]$acceleration
  dat$Ac6 <- t$data[["bodycentre"]]$acceleration
  dat$Ac7 <- t$data[["bcl"]]$acceleration
  dat$Ac8 <- t$data[["bcr"]]$acceleration
  dat$Ac9 <- t$data[["hipl"]]$acceleration
  dat$Ac10 <- t$data[["hipr"]]$acceleration
  dat$Ac11 <- t$data[["tailbase"]]$acceleration
  dat <- as.data.frame(dat) 
  t$features <- abs(dat)
  
  return(t)
}

ZscoreNormalizeFeatures <- function(t, omit = NULL, include = NULL, type = "mean"){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$features)){
    stop("Object has no feature data")
  }
  change <- setdiff(names(t$features),omit)
  if(!is.null(include)){
    change <- intersect(change, include)
  }
  for(i in change){
    if(type == "median"){
      t$features[i] <- NormalizeZscore_median(t$features[i])
    }else if(type == "mean"){
      t$features[i] <- NormalizeZscore(t$features[i])
    }else{
      warning("invalid normalization method")
    }
  }
  return(t)
}

PlotDensityPaths <- function(t,points,SDcutoff = 4, Title = "density path"){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  out <- NULL
  
  SDPlot <- function(x,nSD){
    ifelse((mean(x) - x) / sd(x) > -nSD, x, mean(x) + nSD * sd(x))
  }
  
  for(i in points){
    
    data_plot <- t$data[[i]]
    xbreaks <- seq(floor(min(data_plot$x)), ceiling(max(data_plot$x)), by = 0.1)
    ybreaks <- seq(floor(min(data_plot$y)), ceiling(max(data_plot$y)), by = 0.1)
    data_plot$latbin <- xbreaks[cut(data_plot$x, breaks = xbreaks, labels=F)]
    data_plot$longbin <- ybreaks[cut(data_plot$y, breaks = ybreaks, labels=F)]
    out[[i]] <- ggplot(data = data_plot, aes(x,y)) + 
      stat_density_2d(data = data_plot, aes(latbin,longbin, fill=..density..), geom = "raster", contour = FALSE) + 
      scale_fill_gradient(name = "Time Density", low = "blue", high = "yellow") +
      geom_path(data = data_plot, aes(x,y, color = SDPlot((speed * t$fps),SDcutoff))) + 
      theme_bw() + 
      ggtitle(paste(i,Title, sep = " ")) + 
      scale_color_gradient2(name = paste("speed (",t$distance.units,"/s)",sep = ""), high = "white", low="black", mid = "black")
  }
  return(out)
}


SmoothLabel <- function(x, integration_period){
  types <-unique(x)
  mat <- NULL
  for (i in types){
    mat <- cbind(mat,periodsum(x == i, integration_period))
  }
  c <- apply(mat,1,FUN = which.max)
  return(types[c])
}

AddZonesToPlots <- function(p,z){
  for(i in 1:length(p)){
    for(j in z){
      p[[i]] <- p[[i]] + geom_path(data=j[c(1:nrow(j),1),],aes(x,y))
    }
  }
  return(p)
}

PlotZones <- function(t, zones = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    warning("Zones not defined")
    return(NULL)
  }
  if(is.null(zones)){
    zones <- names(t$zones)
  }
  p <- ggplot()
  for(i in zones){
    dat <- t$zones[[i]]
    p <- p + geom_path(data=dat[c(1:nrow(dat),1),],aes(x,y))
  }
  return(p + theme_bw())
}

AddZones <- function(t,z){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    t$zones <- list()
    t$zones.invert <- list()
  }
  
  for(i in names(z)){
    t$zones[[i]] <- t$median.data[as.character(z[z[,i]!= "",i]),c("x","y")]
    t$zones.invert[[i]] <- FALSE
  }
  return(t)
}

AddBinData <- function(t, bindat = NULL, unit = "frame", binlength = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(!is.null(bindat)){
    if(unit == "second"){
      bindat$from <- bindat$from * t$fps
      bindat$to <- bindat$to * t$fps
    }
    if(unit == "minute"){
      bindat$from <- bindat$from * t$fps * 60
      bindat$to <- bindat$to * t$fps * 60
    }
    t$bins <- bindat
  }else if(!is.null(binlength)){
    binlength <- binlength * ifelse(unit != "frame",t$fps,1) * ifelse(unit == "minute",60,1)
    t$bins <- NULL
    for(i in 1:ceiling(length(t$frames) / binlength)){
      t$bins <- rbind(t$bins, data.frame(bin = paste("bin",i,sep="."), 
                                         from = t$frames[(i-1)*binlength + 1], 
                                         to = t$frames[min(i*binlength,length(t$frames))]))
    }
  }else{
    warning("To add bin data either a the bindata or binlenght has to be added")
  }
  return(t)
}

BinAnalysis <- function(t,FUN, ...){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$bins)){
    warning("No bins defined, can not perform bin analysis")
    return(NULL)
  }
  
  Report <- NULL
  for(i in 1:nrow(t$bins)){
    tb <- CutTrackingData(t, keep.frames = t$bins[i,"from"]:t$bins[i,"to"])
    Report <- rbind(Report,data.frame(bin = t$bins[i,"bin"], FUN(tb,...)$Report))
  }
  return(Report)
}

FSTAnalysis <- function(t, cutoff_floating, integration_period = 0, points, Object){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(sum(t$point.info$PointType == Object) == 0){
    stop("Object to be tracked not available in point info")
  }
  for(i in 1:length(t$data)){
    t$data[[i]]$delta_x <- integratevector(t$data[[i]]$x)
    t$data[[i]]$delta_y <- integratevector(t$data[[i]]$y)
    t$data[[i]]$speed <- sqrt(t$data[[i]]$delta_x ^2 + t$data[[i]]$delta_y^2)
    t$data[[i]]$acceleration <- integratevector(t$data[[i]]$speed)
  }
  
  temp <- t$data[as.character(t$point.info[t$point.info$PointType == Object,"PointName"])]
  acc <- NULL
  for(i in 1:length(temp)){
    acc <- cbind(acc, i = temp[[i]]$acceleration)
  }
  
  t$object <- list()
  t$object$movement <- abs(apply(acc,1,FUN = mean))
  t$object$is.floating <- avgmean(t$object$movement,integration_period) < cutoff_floating
  t$labels$cutoff.floating <- ifelse(t$object$is.floating == 1, "Floating","None")
  
  t$Report <- list()
  t$Report[["time.floating"]] <- sum(t$object$is.floating) / t$fps
  t$Report[["total.time"]] <- length(t$object$is.floating) / t$fps
  t$Report[["percentage.floating"]] <- sum(t$object$is.floating) / length(t$object$is.floating) * 100
  
  for(k in points){
    if(!k %in% names(t$data)){
      stop(paste("point", k, "not vaild", sep = " "))
    }
    t$Report[[paste(k, "raw.distance", sep = ".")]] <- sum(t$data[[k]]$speed, na.rm = T)
    t$Report[[paste(k, "raw.speed", sep = ".")]] <- mean(t$data[[k]]$speed, na.rm = T) * t$fps
    t$Report[[paste(k, "distance.swiming", sep = ".")]] <- sum(t$data[[k]]$speed[!t$object$is.floating], na.rm = T)
    t$Report[[paste(k, "speed.swiming", sep = ".")]] <- mean(t$data[[k]]$speed[!t$object$is.floating], na.rm = T) * t$fps
  }
  
  return(t)
}  

HeadAngleAnalysis <- function(t, points = c("tailbase","neck","neck","nose"), angle_cutoff, integration_period){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  t$object <- list()
  t$object$head.angle.CW <- GetAngleClockwise(t,points[1],points[2],points[3],points[4])
  t$object$head.angle.total <- GetAngleTotal(t,points[1],points[2],points[3],points[4])
  t$object$head.angle.CW.degree <- (t$object$head.angle.CW + pi) * 180 / pi - 180
  t$object$head.angle.total.degree <- t$object$head.angle.total * 180 / pi
  t$object$head.tilted.CW <- t$object$head.angle.CW.degree > angle_cutoff
  t$object$head.tilted.CCW <- t$object$head.angle.CW.degree < -angle_cutoff
  
  t$Report <- list()
  t$Report[["average.head.angle.CW"]] <- mean(t$object$head.angle.CW.degree)
  t$Report[["time.head.tilted.CW"]] <- sum(avgbool(t$object$head.tilted.CW, integration_period)) / t$fps
  t$Report[["time.head.tilted.CCW"]] <- sum(avgbool(t$object$head.tilted.CCW, integration_period)) / t$fps
  
  return(t)
}

GetAngleClockwise <- function(t,p1,p2,p3,p4){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(sum(c(p1,p2,p3,p4) %in% names(t$data)) != 4){
    warning(paste("Points for angle measurement not available in Tracking data:",paste(setdiff(c(p1,p2,p3,p4), names(t$data)),collapse = " "), sep = " "))
    return(NULL)
  }
  
  a1 <- t$data[[p1]]
  a2 <- t$data[[p2]]
  b1 <- t$data[[p3]]
  b2 <- t$data[[p4]]
  ax <- a1$x - a2$x
  ay <- a1$y - a2$y
  bx <- b1$x - b2$x
  by <- b1$y - b2$y
  dot <- ax*bx + ay*by      # dot product between [x1, y1] and [x2, y2]
  det <- ax*by - ay*bx      # determinant
  res <- atan2(det, dot)  # atan2(y, x) or atan2(sin, cos)
  return(res)
}

GetAngleTotal <- function(t,p1,p2,p3,p4){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(sum(c(p1,p2,p3,p4) %in% names(t$data)) != 4){
    warning(paste("Points for angle measurement not available in Tracking data:",paste(setdiff(c(p1,p2,p3,p4), names(t$data)),collapse = " "), sep = " "))
    return(NULL)
  }
  
  a1 <- t$data[[p1]]
  a2 <- t$data[[p2]]
  b1 <- t$data[[p3]]
  b2 <- t$data[[p4]]
  ax <- a1$x - a2$x
  ay <- a1$y - a2$y
  bx <- b1$x - b2$x
  by <- b1$y - b2$y
  
  res <- rep(0,nrow(a1))
  for(i in 1:nrow(a1)){
    res[i] <- acos(sum(c(ax[i],ay[i])*c(bx[i],by[i])) / ( sqrt(sum(c(ax[i],ay[i]) * c(ax[i],ay[i]))) * sqrt(sum(c(bx[i],by[i]) * c(bx[i],by[i]))) ) )
  }
  return(res)
}

CalculateTransitions <- function(x,integration_period){
  x <- avgbool(x,integration_period)
  sum(append(0, (x[2:length(x)]!= x[1:length(x)-1])))
}

avgmean <- function(x, window){
  res <- rep(0, length(x))
  for(i in 1:length(x)){
    res[i] <- mean(x[max(0,i-window):min(length(x), i + window)], na.rm = T)
  }
  return(res)
}

periodsum <- function(x, window){
  res <- rep(0, length(x))
  for(i in 1:length(x)){
    res[i] <- sum(x[max(0,i-window):min(length(x), i + window)], na.rm = T)
  }
  return(res)
}

CreateTrainingSet <- function(t, integration_period, label.group = "manual"){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$labels[[label.group]])){
    stop("manual labels or specified label group does not exist")
  }
  if(is.null(t$features)){
    stop("no feature data available. can not create training set")
  }
  x <- t$features
  x_window <- x[1:(nrow(x) - 2*integration_period),]
  
  if(integration_period > 0){
    for(i in (-integration_period + 1):integration_period){
      x_window <- cbind(x_window, x[(integration_period + i + 1):(nrow(x) - integration_period + i),])
    }
  }
  t$train_x <- as.matrix(x_window)
  t$train_y <- t$labels[[label.group]][(integration_period + 1):(length(t$labels[[label.group]]) - integration_period)]
  t$ml_integration <- integration_period
  return(t)
}

CreateTestSet <- function(t, integration_period){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  x <- t$features
  x_window <- x[1:(nrow(x) - 2*integration_period),]
  
  if(integration_period > 0){
    for(i in (-integration_period + 1):integration_period){
      x_window <- cbind(x_window, x[(integration_period + i + 1):(nrow(x) - integration_period + i),])
    }
  }
  t$train_x <- as.matrix(x_window)
  t$ml_integration <- integration_period
  return(t)
}

ClassifyBehaviors <- function(t,model, model_parameters){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  t <- CreateTestSet(t, model_parameters$integration_period)
  t$labels$classifications <- model %>% predict_classes(t$train_x)
  t$labels$classifications <- c(rep(NA,model_parameters$integration_period), model_parameters$Feature_names[t$labels$classifications + 1], rep(NA,model_parameters$integration_period))
  return(t)
}

PlotLabels <- function(t, p.size = 2){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  dat <- NULL
  
  if(length(t$labels) == 0){
    warning("No labeling data available. can not plot")
    return(NULL)
  }
  
  for(i in names(t$labels)){
    dat <- rbind(dat,data.frame(seconds = t$seconds, behavior =  t$labels[[i]], type = i))
  }
  ggplot(data = na.omit(dat),aes(seconds, behavior, color = behavior)) + 
    geom_point(size = p.size, shape = 124) + 
    facet_grid(type~., scales = "free_y") +
    theme_bw()
}

# We need to modify this function to be able to quantify the time they spend in each area.

PlotZoneVisits <- function(t, points, zones = NULL, p.size = 2){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    warning("no zones defined")
    return(NULL)
  }
  if(is.null(zones)){
    zones <- names(t$zones)
  }
  if(length(setdiff(zones,names(t$zones))) > 0){
    warning("invalid zones")
    return(NULL)
  }
  if(length(setdiff(points,names(t$data))) > 0){
    warning("invalid points")
    return(NULL)
  }
  
  dat <- NULL
  for(j in points){
    for(i in zones){
      dat <- rbind(dat,data.frame(seconds = t$seconds, zone = ifelse(IsInZone(t,j,i,t$zones.invert[[i]]),i,NA), type = "automatic", points = j))
    }
  }
  
  ggplot(data = na.omit(dat),aes(seconds, zone, color = zone)) + 
    geom_point(size = p.size, shape = 124) + 
    facet_grid(points~.) + theme_bw()
}


#Created by IMV (7-23-2023):
PlotDensityPaths_2 <- function(t,points,SDcutoff = 4, Title = "density path"){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  out <- NULL

  SDPlot <- function(x,nSD){
    ifelse((mean(x) - x) / sd(x) > -nSD, x, mean(x) + nSD * sd(x))
  }

  for(i in points){

    data_plot <- t$data[[i]]
    xbreaks <- seq(floor(min(data_plot$x)), ceiling(max(data_plot$x)), by = 0.1)
    ybreaks <- seq(floor(min(data_plot$y)), ceiling(max(data_plot$y)), by = 0.1)
    data_plot$latbin <- xbreaks[cut(data_plot$x, breaks = xbreaks, labels=F)]
    data_plot$longbin <- ybreaks[cut(data_plot$y, breaks = ybreaks, labels=F)]
    out[[i]] <- ggplot(data = data_plot, aes(x,y)) +
      stat_density_2d(data = data_plot, aes(latbin,longbin, fill=..density..), geom = "raster", contour = FALSE) +

      scale_fill_gradientn(colors = c("blue", "orange"), name="Density") +


      # scale_fill_gradient(name = "Time Density", low = "#BBDEFB", high = "red") +
      geom_path(data = data_plot, aes(x,y, color = SDPlot((speed * t$fps),SDcutoff)), size = 0.3, alpha = 1) +
      theme_bw() +
      ggtitle(paste(i,Title, sep = " ")) +
      scale_color_gradient2(name = paste("speed (",t$distance.units,"/s)",sep = ""), high = "red", low= "#FFF59D",  mid = "#FAFAFA")
    # scale_color_gradient(name = paste("speed (",t$distance.units,"/s)",sep = ""), colors = c("4FC3F7","015779B")

  }
  return(out)
}


PlotPointData <- function(t, points = NULL, from = NULL, to = NULL, unit = "frame", type = NULL){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(points) & is.null(type)){
    points <- names(t$data)
  }
  
  if(unit == "second"){
    if(!is.null(from)){
      from <- t$frames[which(t$seconds >= from)[1]]
    }
    if(!is.null(to)){
      to <- t$frames[which(t$seconds >= to)[1]]
    }
  }
  if(is.null(from)){
    from = min(t$frames)
  }
  if(is.null(to)){
    to = max(t$frames)
  }
  
  if(!is.null(type)){
    points <- t$point.info[t$point.info$PointType == type,"PointName"]
  }
  
  range <- from:to
  
  p <- ggdraw()
  dim <- ceiling(sqrt(length(points)))
  nplot <- 0
  
  for(i in points){
    p <- p + draw_plot(ggplot(data = t$data[[i]][t$data[[i]]$frame %in% range,], aes(x,y, color = likelihood)) + geom_path() + ggtitle(i) + xlab(paste("x /",t$distance.units,sep = " ")) + ylab(paste("y /",t$distance.units,sep = " ")) + theme_bw(), 
                       x = (nplot %% dim / dim),
                       y = ((dim - 1)/ dim) - floor(nplot / dim) / dim, 
                       width = 1/dim, 
                       height = 1/dim)
    nplot <- nplot + 1
  }
  
  return(p)
}

pipeline <- function(path){
  Tracking <- ReadDLCDataFromCSV(file = path, fps = 59.94)
  Tracking <- CutTrackingData(Tracking, start = 500,  end = 500)
  Tracking <- CalibrateTrackingData(Tracking, method = "area",in.metric = 24*24,  points = c("tl","tr","br","bl"))
  Tracking <- CleanTrackingData(Tracking, likelihoodcutoff = 0.90)
  Tracking <- AddOFTZones(Tracking, scale_center = 0.5, scale_periphery = 0.8 , scale_corners = 0.4, points = c("tl","tr","br","bl"))
  Tracking <- OFTAnalysis(Tracking, points = "Tailbase", movement_cutoff = 5, integration_period = 5) #There is a warning here about In LabelReport(t, integration_period):no label data present. That's OK.
  return(Tracking)
}

RunPipeline <- function(files, path = NULL, FUN) {
  out <- list()
  
  for (j in files) {
    fullPath <- ifelse(!is.null(path), paste(path, j, sep = ""), j)
    out[[paste(j)]] <- FUN(fullPath)
  }
  
  return(out)
}


# RunPipeline <- function(files, path, FUN){
#   out <- list()
#   for(j in files){
#     out[[paste(j)]] <- FUN(paste(path,j,sep = ""))
#   }
#   return(out)
# }

CombineTrainingsData <- function(ts, shuffle =TRUE){
  if(IsTrackingData(ts)){
    temp <- ts
    ts <- list()
    ts[[paste(temp$filename)]] <- temp
  }
  
  train_x <- NULL
  train_y <- NULL
  for(i in names(ts)){
    if(is.null(ts[[i]]$train_x) | is.null(ts[[i]]$train_y)){
      warning(paste("File:",i,"is missing trainings data. data for this file not included"))
    }else{
      train_x <- rbind(train_x,ts[[i]]$train_x)
      train_y <- append(train_y,ts[[i]]$train_y)
    }
  }
  out <- PrepareMLData(train_x,train_y, shuffle)
  out$parameters$integration_period <- ts[[1]]$ml_integration
  return(out)
}

PrepareMLData <- function(x_train, y_train, shuffle = TRUE){
  if(nrow(x_train) != length(y_train)){
    warning("Unequal size of x_train and y_train")
    return(NULL)
  }
  out <- list()
  parameters <- list()
  x_train <- as.matrix(x_train)
  out$parameters$N_input <- ncol(x_train)
  out$parameters$N_features <- length(unique(y_train))
  out$parameters$Feature_names <- levels(as.factor(y_train))
  
  y_train_cat <- to_categorical(-1 + as.integer(as.factor(y_train)))
  
  if(shuffle){
    new_order <- sample(1:nrow(y_train_cat))
    x_train <- x_train[new_order,]
    y_train_cat <- y_train_cat[new_order,]
  }
  out$train_x <- x_train
  out$train_y <- y_train_cat
  
  return(out)
}

SmoothLabels <- function(t, integration_period){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(t$labels) == 0){
    warning("No labels present. Returning original object")
    return(t)
  }
  for(i in names(t$labels)){
    t$labels[[i]] <- SmoothLabel(t$labels[[i]], integration_period)
  }
  return(t)
}

UnsupervisedClusteringKmeans <- function(ts, N_clusters = 20, Z_score_Normalize = TRUE, dimensions = NULL){
  if(IsTrackingData(ts)){
    print("single file detected. Runing kmeans in single file mode")
    if(is.null(ts$train_x)){
      warning("No training or testing data present. Returning original data")
      return(ts)
    }
    if(Z_score_Normalize){
      test <- kmeans(NormalizeZscore(ts$train_x),centers = N_clusters)
    }
    else{
      test <- kmeans(ts$train_x,centers = N_clusters)
    }
    ts$labels$unsupervised <- c(rep(NA,ts$ml_integration),as.character(test$cluster),rep(NA,ts$ml_integration))
    return(ts)
  }
  
  allx <- NULL
  id <- NULL
  print("multiple files detected. Runing kmeans in multi file mode")
  for(j in names(ts)){
    if(is.null(ts[[j]]$train_x)){
      warning(paste("File:",j, "does not cotain any training data. Returning original data"))
      return(ts)
    }
    allx <- rbind(allx, ts[[j]]$train_x)
    id <- append(id, rep(paste(j),nrow(ts[[j]]$train_x)))
  }
  
  if(Z_score_Normalize){
    allx <- NormalizeZscore(allx)
  }
  
  if(!is.null(dimensions)){
    allx <- svd(allx, nu = dimensions, nv = 0)$u
  }
  
  test <- kmeans(allx,centers = N_clusters)
  
  for(j in names(ts)){
    print(j)
    clust <- test$cluster[id == j]
    ts[[j]]$labels$unsupervised <- c(rep(NA,ts[[j]]$ml_integration),as.character(clust),rep(NA,ts[[j]]$ml_integration))
  }
  return(ts)
}

#' Plots the zone selection of a zone in an object of type TrackingData
#' 
#' @param t a objects of type TrackingData
#' @param point string. name of the point to be plotted
#' @param zones string or vector of strings. name of zones to be selected
#' @param invert boolean. a checkt to determine if the zone or a inversion of the zone should be used. defaults to FALSE
#' @return a plot
#' @examples
#' MultiFileReport(TrackingAll)
#'
PlotZoneSelection <- function(t,point,zones, invert = FALSE){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(!point %in% names(t$data)){
    warning("Invalid point")
    return(NULL)
  }
  if(!sum(zones %in% names(t$zones))){
    warning("Invalid zone(s)")
    return(NULL)
  }
  
  dat <- t$data[[point]]
  in.zone <- rep(FALSE,nrow(dat))
  for(i in t$zones[zones]){
    in.zone <- in.zone | (point.in.polygon(dat$x,dat$y,i$x,i$y) == 1)
  }
  if(invert){
    in.zone <- !in.zone
  }
  p <- ggplot(dat,aes(x,y, color = in.zone)) + geom_point() + theme_bw()
  return(p)
}

#' Creates a combined report of all files in a list of TrackingData objects
#' 
#' @param ts list of objects of type TrackingData
#' @return a data.frame
#' @examples
#' MultiFileReport(TrackingAll)
#'
MultiFileReport <- function(ts){
  if(IsTrackingData(ts)){
    stop("Expected a list() of TrackingData objects. You entered a single object")
  }
  out <- list()
  for(i in names(ts)){
    if(IsTrackingData(ts[[i]])){
      if(is.null(ts[[i]]$Report)){
        warning(paste("Object",i,"Does not contain any Report. omitting", sep = " "))
      }else{
        out <- rbindlist(list(out,append(c(file = ts[[i]]$filename), ts[[i]]$Report)),use.names = TRUE, fill = TRUE,idcol = F)
      }
    }else{
      warning(paste("List contains an element that is not of type TrackingData:",i,".No report produced for these", sep = " "))
    }
  }
  return(data.frame(out))
}

#' Performs a specified analysis on a list() of TrackingData objects and produces a final report
#' 
#' @param ts list of objects of type TrackingData
#' @param FUN An analysis function that should be applied to bins
#' @param ... any paramteres that are required for the function FUN
#' @return a data.frame
#' @examples
#' MultiFileBinanalysis(TrackingAll, FUN = OFTAnalysis, movement_cutoff = 5,integration_period = 5,points = "bodycentre")
#'
MultiFileBinanalysis <- function(ts, FUN, ...){
  if(IsTrackingData(ts)){
    stop("Expected a list() of TrackingData objects. You entered a single object")
  }
  out <- NULL
  for(i in names(ts)){
    if(IsTrackingData(ts[[i]])){
      binrep <- BinAnalysis(ts[[i]], FUN = FUN, ...)
      out <- rbind(out, data.frame(file = i, binrep))
    }else{
      warning(paste("Object",i,"is not of type Tracking data. omiting from Analysis", sep = " "))
    }
  }
  return(out)
}

#' Creates an density path plot pdf for one or multiple objects of type TrackingData
#' 
#' @param ts list or single object of type TrackingData
#' @param points A string or vector of strings. name of the point(s) to be plotted
#' @param filename A string. the name of the pdf file. defaults to "DensityPathMulti"
#' @param width a numeric value. width of the plot in inch. defaults to 10
#' @param height a numeric value. height of the plot in inch. defaults to 8
#' @param add_zones a boolean check. should zones be plotted to the density path? requires all objects to have zones. default to FALSE
#' @param selected_zones a string or vector of strings. zone names of the zones to be plotted. default to NULL (= plot all)
#' @param ... any parameter(s) that is used for the function PlotZoneVisits()
#' @return NULL. creates a pdf file in the working directory
#' @examples
#' PlotZoneVisits.Multi.PDF(TrackingAll, filename = "MyZoneVisits")
#'
PlotDensityPaths.Multi.PDF <- function(ts, points, filename = "DensityPathMulti",width = 10, height = 8, add_zones = FALSE, selected_zones = NULL, ...){
  if(IsTrackingData(ts)){
    x <- ts
    ts <- list()
    ts[[paste(x$filename)]] <- x
  }
  out <- list()
  for(i in names(ts)){
    if(IsTrackingData(ts[[i]])){
      ps <- PlotDensityPaths(ts[[i]],points = points, Title = i, ...)
      
      if(add_zones){
        if(!is.null(ts[[i]]$zones)){
          if(is.null(selected_zones)){
            zones <- names(ts[[i]]$zones)
          }else{
            zones <- intersect(names(ts[[i]]$zones), selected_zones)
          }
          if(length(zones) == 0){
            warning(paste("in file:", i, "none of the indicated zones found in data", sep = " "))
          }
          else{
            ps <- AddZonesToPlots(ps,ts[[i]]$zones[zones])
          }
        }else{
          warning(paste("can not add zones to",i, ".Does not have zones defined", sep = " "))
        }
      }
      out <- append(out,ps)
    }else{
      warning(paste("List contains an element that is not of type TrackingData:",i,".No plot produced for these", sep = " "))
    }
  }
  pdf(paste(filename,".pdf",sep = ""), width = width, height = height)
  for(i in out){
    print(i)
  }
  dev.off()
  return(NULL)
}

#' Creates an zone visit plot pdf for one or multiple objects of type TrackingData
#' 
#' @param ts list or single object of type TrackingData
#' @param filename A string. the name of the pdf file. defaults to "ZoneVisitsMulti"
#' @param width a numeric value. width of the plot in inch. defaults to 10
#' @param height a numeric value. height of the plot in inch. defaults to 8
#' @param ... any parameter(s) that is used for the function PlotZoneVisits()
#' @return NULL. creates a pdf file in the working directory
#' @examples
#' PlotZoneVisits.Multi.PDF(TrackingAll, filename = "MyZoneVisits")
#'
PlotZoneVisits.Multi.PDF <- function(ts, points,filename = "ZoneVisitsMulti", width = 10, height = 8,...){
  if(IsTrackingData(ts)){
    x <- ts
    ts <- list()
    ts[[paste(x$filename)]] <- x
  }
  
  pdf(paste(filename,".pdf",sep = ""), width = width, height = height)
  for(i in names(ts)){
    print(PlotZoneVisits(ts[[i]], points,...) + ggtitle(paste(i)))
  }
  dev.off()
  return(NULL)
}

#' Creates an labels plot pdf for one or multiple objects of type TrackingData
#' 
#' @param ts list or single object of type TrackingData
#' @param filename A string. the name of the pdf file. defaults to "LabelsMulti"
#' @param width a numeric value. width of the plot in inch. defaults to 10
#' @param height a numeric value. height of the plot in inch. defaults to 8
#' @param ... any parameter(s) that is used for the function PlotLabels()
#' @return NULL. creates a pdf file in the working directory
#' @examples
#' PlotLabels.Multi.PDF(TrackingAll, filename = "MyLabels")
#'
PlotLabels.Multi.PDF <- function(ts, filename = "LabelsMulti", width = 10, height = 8, ...){
  if(IsTrackingData(ts)){
    x <- ts
    ts <- list()
    ts[[paste(x$filename)]] <- x
  }
  
  pdf(paste(filename,".pdf",sep = ""), width = width, height = height)
  for(i in names(ts)){
    print(PlotLabels(ts[[i]],...) + ggtitle(paste(i)))
  }
  dev.off()
  return(NULL)
}

#' Creates an overview plot for a object of type TrackingData
#' 
#' @param t object of type TrackingData
#' @param point a string indicating the name of the point to be plotted
#' @return a plot
#' @examples
#' NormalizeZscore(Trackingdata, point = "bodycentre")
#'
OverviewPlot <- function(t, point){
  if(!IsTrackingData(t)){
    stop("Input needs to be a single object of type Tracking")
  }
  if(!point %in% names(t$data)){
    warning("point does not exist in Trackingobject")
  }
  
  rel_h <- c(0.2,1.5)
  title <- ggdraw() + draw_label(paste("Overview file",t$filename, sep = " "))
  p1 <- PlotDensityPaths(t,point)
  if(!is.null(t$zones)){
    p1 <- AddZonesToPlots(p1, t$zones)
  }
  p1 <- p1[[1]] + scale_y_reverse()
  
  if(length(t$labels) > 0){
    p2 <- PlotLabels(t) +  theme(legend.position = "none")
    rel_h <- append(rel_h, 0.5)
  }
  if(!is.null(t$zones)){
    p3 <- PlotZoneVisits(t,points = point) +  theme(legend.position = "none")
    rel_h <- append(rel_h, 0.5)
  }
  
  if((length(t$labels) > 0) & !is.null(t$zones)){
    return(plot_grid(title,p1,p2,p3,rel_heights = rel_h, ncol = 1))
  }else if(length(t$labels) > 0){
    return(plot_grid(title,p1,p2,rel_heights = rel_h, ncol = 1))
  }else if(!is.null(t$zones)){
    return(plot_grid(title,p1,p3,rel_heights = rel_h, ncol = 1))
  }
  else{
    return(plot_grid(title,p1,rel_heights = rel_h, ncol = 1))
  }
}

#' mean Zscore normalization of a numeric matrix across columns
#' 
#' @param x a numeric matrix
#' @return a numeric matrix
#' @examples
#' NormalizeZscore(mymatrix)
#'
NormalizeZscore <- function(x){
  apply(x, 2, FUN = function(x){(x - mean(x)) / (sd(x))})
}

#' median Zscore normalization of a numeric matrix across columns
#' 
#' @param x a numeric matrix
#' @return a numeric matrix
#' @examples
#' NormalizeZscore_median(mymatrix)
#'
NormalizeZscore_median <- function(x){
  apply(x, 2, FUN = function(x){(x - median(x)) / (sd(x))})
}

#' integration of a numeric vector
#' 
#' @param x a numeric vector
#' @return a numeric vector
#' @examples
#' integratevector(myvector)
#'
integratevector <- function(x){
  if(length(x) < 2){
    stop("can  not integrate a vector of length < 2")
  }
  append(0, x[2:length(x)] - x[1:(length(x)-1)])
}

#' Boolean smoothing over an integration period
#' 
#' @param x a boolean vector
#' @param window a integration window length (in +- window entries)
#' @return a boolean vector
#' @examples
#' avgbool(booleanvector, window = 10)
#' 
avgbool <- function(x, window){
  res <- rep(0, length(x))
  for(i in 1:length(x)){
    res[i] <- mean(x[max(0,i-window):min(length(x), i + window)], na.rm = T) > 0.5
  }
  return(res)
}

#' Equalizes a training set so every group is equaly represented
#' 
#' @param x the training data
#' @param y the categorical labeling data (as produced by the library(keras) funciton to_categorical)
#' @return a list with 2 elements, adjusted x and adjusted y
#' @examples
#' EqualizeTrainingSet(x_train,y_train)
#' 
EqualizeTrainingSet <- function(x,y){
  N_obs <- NULL
  for(i in 1:ncol(y)){
    N_obs <- append(N_obs,sum(y[,i]))
  }
  
  keep <- rep(FALSE,nrow(y))
  
  for(i in 1:ncol(y)){
    keep[sample(which(y[,i] == 1))[1:min(N_obs)]] <- TRUE
  }
  out <- list()
  out$x <- x[keep,]
  out$y <- y[keep,]
  return(out)
}


#' Evaluates the performance of the classifier across one or mutlipe TrackingData objects by comparing a ground truth to any label
#' 
#' @param ts a list of objects of type TrackingData or a single object of type TrackingData
#' @param truth name of the label group that is considered the ground truth. by default "manual"
#' @param compare name of the label group that is considered the label to compare. by default "classifications"
#' @return a Report object with two sub-object, each a data.frame for the evaluation across or within files
#' @examples
#' EvaluateClassification(ts)
#' EvaluateClassification(ts, truth = "manual", compare = "classifications")
#' 
EvaluateClassification <- function(ts, truth = "manual", compare = "classifications"){
  if(IsTrackingData(ts)){
    x <- ts
    ts <- list()
    ts[[paste(x$filename)]] <- x
  }
  Report <- list()
  Report$files <- NULL
  for(i in names(ts)){
    if(is.null(ts[[i]]$labels)){
      stop(paste("file",i,"Does not have label data", sep = " "))
    }
    if(is.null(ts[[i]]$labels[[truth]])){
      stop(paste("file",i,"Does not have label type", truth, sep = " "))
    }
    if(is.null(ts[[i]]$labels[[compare]])){
      stop(paste("file",i,"Does not have label type", compare, sep = " "))
    }
    for(j in na.omit(unique(ts[[i]]$labels[[compare]]))){
      precision <- sum(ts[[i]]$labels[[compare]] == j & ts[[i]]$labels[[truth]] == j, na.rm = T) / sum(ts[[i]]$labels[[compare]] == j, na.rm = T)
      N_truth = sum(ts[[i]]$labels[[truth]] == j, na.rm = T)
      N_compare = sum(ts[[i]]$labels[[compare]] == j, na.rm = T)
      correct <- sum(ts[[i]]$labels[[compare]] == j & ts[[i]]$labels[[truth]] == j, na.rm = T)
      wrong <- sum(ts[[i]]$labels[[compare]] != j & ts[[i]]$labels[[truth]] == j, na.rm = T)
      recall <- sum(ts[[i]]$labels[[compare]] == j & ts[[i]]$labels[[truth]] == j, na.rm = T) / sum(ts[[i]]$labels[[truth]] == j, na.rm = T)
      Report$files <- rbind(Report$files,data.frame(file = i, 
                                                    label = j, 
                                                    accuracy = correct/(correct + wrong),
                                                    precision = correct / N_compare, 
                                                    recall = correct / N_truth,
                                                    correct = correct, 
                                                    wrong = wrong, 
                                                    N_truth = N_truth, 
                                                    N_compare = N_compare))
    }
    
  }
  
  Report$overall <- NULL
  for(i in unique(Report$files$label)){
    s <- apply(Report$files[Report$files$label == i,-c(1:5)],2,FUN = sum)
    Report$overall <- rbind(Report$overall, data.frame(label = i,
                                                       accuracy = s[1]/(s[1] +s[2]), 
                                                       precision =  s[1] / s[4], 
                                                       recall =   s[1] / s[3],
                                                       correct = s[1],
                                                       wrong = s[2],
                                                       N_truth = s[3],
                                                       N_compare = s[4]
    ))
  }
  return(Report)
}


#' Creates correlation plots between different labels over multiple files
#' 
#' @param ts a list of objects of type TrackingData
#' @param include a character vector that describes which labels to include. defaults to all
#' @param smooth a integer that describes over how many frames labels should be smoothed. defaults to NULL = no smoothing.
#' @param hclust a boolean that decides if plots should be ordered by hclust
#' @return a correlation plot
#' @examples
#' CorrelationPlotLabels(ts)
#' CorrelationPlotLabels(ts, include = c("manual.Unsupported.count","classification.Unsupported.count","manual.Supported.count","classification.Supported.count"), hclust = TRUE)
#' 
CorrelationPlotLabels <- function(ts, include = NULL, smooth = NULL, hclust = FALSE){
  compare <- list()
  for(i in ts){
    if(!is.null(smooth)){
      i <- SmoothLabels(i, smooth)
    }
    compare <- rbindlist(list(compare,LabelReport(i)),use.names = TRUE, fill = TRUE,idcol = F)
  }
  compare <-as.data.frame(compare)
  
  if(is.null(include)){
    include <- names(compare)
  }
  
  if(hclust){
    corrplot(cor(as.matrix(na_replace(compare[,include]))),title = "Correlation Plot", 
             method = "square", 
             outline = T, 
             addgrid.col = "darkgray", 
             order="hclust")
  }else{
  corrplot(cor(as.matrix(na_replace(compare[,include]))),
           method="color",
           type = "upper",
           addCoef.col = "black")
  }
}

#' Extracts labels from a long format data.frame
#' 
#' @param lab a long format data frame with labeling data
#' @param Experimenter a character or vector of character. the name of the experimenter(s) that should be extracted
#' @param type a character or vector of character. the name of type(s) that should be extracted
#' @param DLCFile a character or vector of character. the name of DLCFile(s) that should be extracted
#' @param ID a character or vector of character. the name of ID(s) that should be extracted
#' @return a data.frame extracted labels
#' @examples
#' ExtractLabels(lab, Experimenter = "Oliver", DLCFile = "FST_1.csv")
#' ExtractLabels(lab, Experimenter = "Oliver", type = c("Supported","Unsupported"))
#' 
ExtractLabels <- function(lab, Experimenter=NULL, type = NULL, DLCFile = NULL, ID = NULL){
  if(!is.null(Experimenter)){
    lab <- lab[lab$Experimenter %in% Experimenter,]
  }
  if(!is.null(type)){
    lab <- lab[lab$type %in% type,]
  }
  if(!is.null(DLCFile)){
    lab <- lab[lab$DLCFile %in% DLCFile,]
  }
  if(!is.null(ID)){
    lab <- lab[lab$ID %in% ID,]
  }
  return(lab)
}

#' Linearly scales a number of features by a set scaling factor
#' 
#' @param feat a numeric data.frame or matrix
#' @param select if set, a vector of column names that should be scaled. otherwise all will be scaled
#' @param factor vector of column names that should be scaled
#' @return a numeric data.frame or matrix
#' @examples
#' ScaleFeatures(feat, factor = 0.3)
#' ScaleFeatures(feat, select = c("feat1","feat3"), factor = 2)
#'
ScaleFeatures <- function(feat, select = NULL, factor){
  if(is.null(select)){
    feat <- names(feat)
  }
  feat[,select] <- feat[,select] * factor
  return(feat)
}

#' Combines multiple specified labels into a new, seperate label
#' 
#' @param ts a list of objects of type TrackingData or a single object of type TrackingData
#' @param which.lab the name of the label group that should be used, defaults to "unsupervised"
#' @param by a vector of label names that should be aggregated
#' @param name a string that contains the name of the newly created lable group
#' @return a list of objects of type TrackingData or a single object of type TrackingData
#' @examples
#' CombineLabels(ts, which.lab = "manual", by = c("Unsupported","Supported"), name = "AllRears")
#' CombineLabels(ts, which.lab = "unsupervised", by = list(c("cluster1","cluster2"),c("cluster5","cluster12","cluster6"),c("cluster8")), name = "CombinedClusters")
#' 
CombineLabels <- function(ts, which.lab = "unsupervised", by, name = "combined"){
  if(IsTrackingData(ts)){
    x <- ts
    ts <- list()
    ts[[paste(x$filename)]] <- x
  }
  
  for(i in names(ts)){
    if(!IsTrackingData(ts[[i]])){
      stop(paste("element",i,"is not of type TrackingData", sep = " "))
    }
    if(is.null(ts[[i]]$labels)){
      warning(paste("element",i,"has no labeling data", sep = " "))
      return(ts)
    }
    if(is.null(ts[[i]]$labels[[which.lab]])){
      warning(paste("element",i,"has no labeling data of type", which.lab, sep = " "))
      return(ts)
    }
    cdat <- ts[[i]]$labels[[which.lab]]
    out <- rep("None", length(ts[[i]]$labels[[which.lab]]))
    for(j in by){
      out[cdat %in% j] <- paste(j, collapse = ".")
    }
    ts[[i]]$labels[[name]] <- out
  }
  if(length(ts) > 1){
  return(ts)
  }
  return(ts[[1]])
}


#' Calculates the minimum distance of a point to a zone
#' 
#' @param t an object of type TrackingData
#' @param zone a name of zone (has to be present in t)
#' @param point a name of point (has to be present in t)
#' @return an array of distances of point p to edge of the zone at each frame
#' @examples
#' GetDistanceToZoneBorder(t = Tracking, zone = "arena", point = "bodycentre")
#' 
GetDistanceToZoneBorder <- function(t,zone,point){
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(is.null(t$zones)){
    stop("TrackingData object has no zones")
  }
  if(!(zone %in% names(t$zones))){
    stop("invalid zone")
  }
  if(!(point %in% names(t$data))){
    stop("invalid point")
  }
  return(DistanceToPolygon(t$data[[point]][,c("x","y")], t$zones[[zone]][,c("x","y")]))
}

#' Calculates the minimum distance of a point p to any edge of a polygon pol
#' 
#' @param p a list() or data.frame() of a point. needs to contain p$x and p$y
#' @param pol a data.frame() of a polygon. needs to contain at least to columns, pol$x and pol$y
#' @return an object of type TrackingData 
#' @examples
#' DistanceToPolygon(p = data.frame(x = 0.5, y = 0.7), pol = data.frame(x = c(1,1,0,0), y = c(1,0,0,1)))
#' 
DistanceToPolygon <- function(p,pol){
  dist2d <- function(a,b,c){
    v1x <- b$x - c$x
    v1y <- b$y - c$y
    v2x <- a$x - b$x
    v2y <- a$y - b$y
    det <- v1x*v2y - v1y*v2x 
    
    d <- abs(det)/sqrt(v1x*v1x + v1y*v1y)
    return(d)
  } 
  
  pol <- pol[c(1:nrow(pol),1),]
  dist <- NULL
  
  for(i in 1:(nrow(pol) - 1)){
    dist <-  cbind(dist,dist2d(p, pol[i,], pol[i + 1,]))
  }
  return(apply(dist, 1, FUN=min))
}

#' Rotates an object of type Tracking data around a center of gravity defined by a number of points. rotation can be defined in degree, or alternatively a line of to points can be set parallel to the x-axis
#' 
#' @param t an object of type TrackingData
#' @param theta an angle in degree
#' @param center.of a vector of point names used to define a rotation center (mean value of x and y coordinats of the specified points)
#' @param set.straight.to.x a vector with the names of two points that define a line that should be set parallel to the x-axis
#' @return an object of type TrackingData 
#' @examples
#' RotateTrackingData(t = Tracking,theta = 45, center.of = c("tl","tr","bl","br"))
#' RotateTrackingData(t = Tracking,set.straight.to.x = c("br","tr"), center.of = c("tl","tr","bl","br"))
#' 
RotateTrackingData <- function(t, theta = 0, center.of = c("tl","tr","bl","br"), set.straight.to.x = NULL){
  theta <- theta * pi / 180
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(sum(center.of %in% names(t$data)) != length(center.of)){
    stop("invalid points selected for center.of")
  }
  if(!is.null(set.straight.to.x)){
    if(length(set.straight.to.x) != 2 | sum(set.straight.to.x %in% names(t$data)) != 2){
      stop("invalid set.straigth.to.x: needs to be a vector with valid point names of exactly 2 points that define a line")
    }
    ax <- t$median.data[set.straight.to.x[2],"x"] - t$median.data[set.straight.to.x[1],"x"] 
    ay <- t$median.data[set.straight.to.x[2],"y"] - t$median.data[set.straight.to.x[1],"y"] 
    print(ax)
    print(ay)
    theta = -acos(abs(ax) / sqrt(ax*ax + ay*ay))
  }
  center_x <- mean(t$median.data[center.of,"x"])
  center_y <- mean(t$median.data[center.of,"y"])
  
  if(!is.null(t$zones)){
    for(i in names(t$zones)){
      old_x <- t$zones[[i]]$x - center_x
      old_y <- t$zones[[i]]$y - center_y
      t$zones[[i]]$x <- old_x * cos(theta) - old_y * sin(theta) + center_x
      t$zones[[i]]$y <- old_x * sin(theta) + old_y * cos(theta) + center_y
    }
  }
  for(i in names(t$data)){
    old_x <- t$data[[i]]$x - center_x
    old_y <- t$data[[i]]$y - center_y
    t$data[[i]]$x <- old_x * cos(theta) - old_y * sin(theta) + center_x
    t$data[[i]]$y <- old_x * sin(theta) + old_y * cos(theta) + center_y
  }
  
  old_x <- t$median.data$x - center_x
  old_y <- t$median.data$y - center_y
  t$median.data$x <- old_x * cos(theta) - old_y * sin(theta) + center_x
  t$median.data$y <- old_x * sin(theta) + old_y * cos(theta) + center_y
  return(t)
}

apply_all_functions <- function(TrackingAll) {
  # Initialize vectors to store the results
  names_vector <- c()
  area_results <- c()
  length_results <- c()
  paw_distance_results <- list()
  stride_length_results <- list()
  step_width_results <- c()
  group_results <- c()
  
  # Replace the names of the files by control and mutant
  replace_names <- function(df, column_name) {
    df[[column_name]] <- ifelse(grepl("control", df[[column_name]], ignore.case = TRUE), "Control", df[[column_name]])
    df[[column_name]] <- ifelse(grepl("mutant", df[[column_name]], ignore.case = TRUE), "Mutant", df[[column_name]])
    return(df)
  }
  
  # Loop over each data frame in the list. 
  for (name in names(TrackingAll)) {
    # Apply replace_names to each data frame
    TrackingAll[[name]] <- replace_names(TrackingAll[[name]], "file")
    
    # Apply MedianMouseArea and store the result. Here, we are not filtering for the speed. We calculate the average area in the entire video. 
    area_results <- c(area_results, MedianMouseArea(TrackingAll[[name]], points = c("Snout", "Head", "Tailbase", "RF_paw", "LF_paw", "RB_paw", "LB_paw")))
    
    # Apply MedianMouseLength and store the result. Here, we are not filtering for the speed. 
    length_results <- c(length_results, MedianMouseLength(TrackingAll[[name]], front = "Snout", back = "Tailbase"))
    
    # Apply calculate_paw_distance and store the result. This function filters for moments in which the animal is walking with a speed threshold of >0.05 (at P15)
    paw_distance_results[[name]] <- calculate_paw_distance(TrackingAll[[name]]) 
    
    # Apply calculate_stride_length and store the result
    stride_length_results[[name]] <- calculate_stride_length(TrackingAll[[name]])
    
    
    # Apply calculate_step_width and store the result
    step_width_results <- c(step_width_results, calculate_step_width(TrackingAll[[name]]))
    
    # Store the name
    names_vector <- c(names_vector, name)
    
    # Store the group
    group_results <- c(group_results, ifelse(grepl("control", name, ignore.case = TRUE), "Control", "Mutant"))
  }
  
  # Create a data frame with the results
  df <- data.frame(
    name = names_vector,
    group = group_results,
    area = area_results,
    length = length_results,
    step_width = step_width_results
  )
  
  # Add the results from paw_distance_results and stride_length_results to the data frame
  for (name in names_vector) {
    df[df$name == name, c("Front_paw_distance_mean", "Front_paw_distance_sd", "Back_paw_distance_mean", "Back_paw_distance_sd")] <- unlist(paw_distance_results[[name]])
    df[df$name == name, c("mean_stride_length", "sd_stride_length")] <- unlist(stride_length_results[[name]])
  }
  
  # Create box plots for each numeric variable (excluding sd and sem)
  boxplots <- lapply(names(df[, sapply(df, is.numeric) & !grepl("sd|sem", names(df))]), function(x) {
    y_label <- switch(x,
                      area  = "mouse area (cm2)",
                      length = "mouse length (cm)",
                      Front_paw_distance_mean = "Front paw distance (cm)",
                      Back_paw_distance_mean = "Back paw distance (cm)",
                      mean_stride_length = "Stride length (cm)",
                      Stride_length_left_mean = "Stride length left (cm)",
                      step_width = "Step width (cm)",
                      x)
    ggplot(df, aes(x = group, y = df[[x]], color = group)) +
      geom_boxplot(width = 0.4) +
      # geom_point(aes(x = group, y = df[[x]]),stat="identity",
      #         position_jitterdodge(jitter.width = 0.18,dodge.width=0.8),
      #        alpha=0.5,
      #        size=5,
      #        shape = 21) +
      geom_jitter(width = 0.2, alpha = 0.5, size = 3) +
      labs(x = "", y = y_label) +
      # stat_compare_means(method = "t.test", label = "p.signif") +
      scale_color_manual(values = c("Control" = "dodgerblue", "Mutant" = "red"))  
  })
  
  
  table <- df[,-1] %>%
    kable("latex", booktabs = TRUE) %>%
    kable_styling(latex_options = c("scale_down", "hold_position"))
  
  # Write the LaTeX code to a .tex file
  writeLines(c("\\documentclass{article}",
               "\\usepackage{booktabs}",
               "\\usepackage{geometry}",
               "\\usepackage{lscape}",
               "\\geometry{a4paper, margin=1in}",
               "\\begin{document}",
               "\\begin{landscape}",
               "\\begin{center}",
               table,
               "\\end{center}",
               "\\end{landscape}",
               "\\end{document}"), "table.tex")
  
  # Use pdflatex to convert the .tex file to a PDF
  system("pdflatex table.tex")
  
  #Generate a csv file from the dataframe:
  write.csv(df, "table.csv")
  
  all_plots <- c(boxplots)
  
  # Save all plots to a single PDF file
  g <- marrangeGrob(grobs = all_plots, nrow=3, ncol=2, top = NULL)
  ggsave("plots.pdf", g, width = 8.5, height = 11)
  
  # Return the data frame and the plots
  # return(list(df = df, boxplots = boxplots, barplots = barplots))  
  return(list(df = df, boxplots = boxplots))  
  
}

# generate_report <- function(TrackingAll) {
#   Report <- MultiFileReport(TrackingAll)
#   Report <- as.data.frame(Report[,1:9])
#   
#   # Replace names and add group column if needed
#   replace_names <- function(df, column_name) {
#     df[[column_name]] <- ifelse(grepl("control", df[[column_name]], ignore.case = TRUE), "Control", "Mutant")
#     return(df)
#   }
#   Report <- replace_names(Report, "file")
#   
#   if (!"group" %in% names(Report)) {
#     Report$group <- ifelse(grepl("Control", Report$file), "Control", "Mutant")
#   }
#   
#   # Calculate stats
#   calculate_stats <- function(df) {
#     df %>% 
#       group_by(group) %>%
#       summarise(across(where(is.numeric), list(mean = mean, sd = sd, sem = ~sd(.)/sqrt(length(.)))))
#   }
#   stats <- calculate_stats(Report)
#   
#   # Create bar plots for each numeric variable (excluding sd and sem):
#   barplots <- lapply(names(Report[, sapply(Report, is.numeric)]), function(x) {
#     y_label <- switch(x,
#                       "Tailbase.raw.distance" = "Distance moved (cm)",
#                       "Tailbase.speed.moving" = "Speed (cm/s)",
#                       "Tailbase.distance.moving" = "Distance moving (cm)",
#                       "Tailbase.time.moving" = "Time moving (s)",
#                       "Tailbase.raw.speed" = "Raw speed (cm/s)",
#                       "Tailbase.total.time" = "Total time (s)",
#                       "Tailbase.time.stationary" = "Time not moving (s)",
#                       "Tailbase.percentage.moving" = "% moving",
#                       x)
#     
#     ggplot(Report, aes(x = group, y = .data[[x]], fill = group)) +
#       stat_summary(fun = mean, geom = "bar", position = position_dodge(), width = 0.6) +
#       stat_summary(fun.data = mean_se, geom = "errorbar", position = position_dodge(0.6), width = 0.2) +
#       geom_jitter(position = position_jitterdodge(jitter.width = 0.1), alpha = 0.4) +
#       labs(x = "", y = y_label) +
#       theme_minimal()+
#       tryCatch({
#         stat_compare_means(method = "t.test", label = "p.signif")
#       }, error = function(e) {
#         # Optionally log the error message
#         message("Error in stat_compare_means for variable ", x, ": ", e$message)
#         NULL  # Return NULL to exclude the layer from the plot
#       })
# 
#   })
#   
#   all_plots <- c(barplots)
#   
#   # Save plots to PDF
#   g <- marrangeGrob(grobs = all_plots, nrow=3, ncol=2, top = NULL)
#   ggsave("plots_2.pdf", g, width = 8.5, height = 11)
#   
#   return(list(stats = stats, barplots = barplots))
# }
# 
# 
# generate_report <- function(TrackingAll) {
#   
#   Report <- MultiFileReport(TrackingAll)
#   Report <- as.data.frame(Report[,1:9])
#   
#   # Replace the names of the files by control and mutant
#   replace_names <- function(df, column_name) {
#     df[[column_name]] <- ifelse(grepl("control", df[[column_name]], ignore.case = TRUE), "Control", df[[column_name]])
#     df[[column_name]] <- ifelse(grepl("mutant", df[[column_name]], ignore.case = TRUE), "Mutant", df[[column_name]])
#     return(df)
#   }
#   
#   Report <- replace_names(Report, "file")
#   
#   # Create the group variable and remove the file column
#   Report$group <- ifelse(grepl("Control", Report$file), "Control", "Mutant")
#   Report$file <- NULL
#   
#   
#   # Define a function to calculate the stats
#   calculate_stats <- function(df) {
#     df %>% 
#       group_by(group) %>%
#       summarise(across(where(is.numeric), list(mean = mean, sd = sd, sem = ~sd(.)/sqrt(length(.)))))
#   }
#   
#   # Apply the function
#   stats <- calculate_stats(Report)
#   
#   # Move the group variable to the first column
#   stats <- stats %>% dplyr::select(group, everything())
#   
#   colnames(stats)
#   
#   
#   barplots <- lapply(names(Report[, sapply(Report, is.numeric)]), function(x) {
#     y_label <- switch(x,
#                       "Tailbase.raw.distance" = "Distance moved (cm)",
#                       "Tailbase.speed.moving" = "Speed (cm/s)",
#                       "Tailbase.distance.moving" = "Distance moving (cm)",
#                       "Tailbase.time.moving" = "Time moving (s)",
#                       "Tailbase.raw.speed" = "Raw speed (cm/s)",
#                       "Tailbase.total.time" = "Total time (s)",
#                       "Tailbase.time.stationary" = "Time not moving (s)",
#                       "Tailbase.percentage.moving" = "% moving",
#                       x)
#     
#     ggplot(Report, aes(x = group, y = .data[[x]], fill = "white", color = group)) +
#       # Add bar for mean
#       stat_summary(fun.data = function(y) {
#         return(c(ymin = mean(y) - sd(y),
#                  ymax = mean(y) + sd(y)))
#       }, geom = "errorbar", position = position_dodge(0.6), width = 0.2) +  # Change from "linerange" to "errorbar" and add width argument
#       stat_summary(fun = mean, geom = "bar", position = position_dodge(), width = 0.6) +
#       geom_jitter(position = position_jitterdodge(jitter.width = 0.3), alpha = 0.4, size = 3) +
#       scale_color_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#       scale_fill_manual(values = "white") +
#       scale_y_continuous(expand = c(0, 0.8)) +  # Here we set the multiplicative constant to 0
#       labs(x = "", y = y_label) +
#       tryCatch({
#         stat_compare_means(method = "t.test", label = "p.signif")
#       }, error = function(e) {
#         geom_blank()  # return a blank geom if a t-test can't be performed
#       }) 
#     # theme_minimal()
#   })
#   
#   
#   # Combine boxplots and barplots
#   all_plots <- c(barplots)
#   
#   # Save all plots to a single PDF file
#   g <- marrangeGrob(grobs = all_plots, nrow=3, ncol=2, top = NULL)
#   ggsave("plots_2.pdf", g, width = 8.5, height = 11)
#   
#   # Return the transposed data frame and the plots
#   return(list(stats = stats, barplots = barplots))
# }

generate_report <- function(TrackingAll) {
  
  Report <- MultiFileReport(TrackingAll)
  Report <- as.data.frame(Report[,1:9])
  
  # Replace the names of the files by control and mutant
  replace_names <- function(df, column_name) {
    df[[column_name]] <- ifelse(grepl("control", df[[column_name]], ignore.case = TRUE), "Control", df[[column_name]])
    df[[column_name]] <- ifelse(grepl("mutant", df[[column_name]], ignore.case = TRUE), "Mutant", df[[column_name]])
    return(df)
  }
  
  Report <- replace_names(Report, "file")
  
  # Create the group variable and remove the file column
  Report$group <- ifelse(grepl("Control", Report$file), "Control", "Mutant")
  Report$file <- NULL
  
  
  # Define a function to calculate the stats
  calculate_stats <- function(df) {
    df %>%
      group_by(group) %>%
      summarise(across(where(is.numeric), list(mean = mean, sd = sd, sem = ~sd(.)/sqrt(length(.)))))
  }
  
  # Apply the function
  stats <- calculate_stats(Report)
  
  
  # Move the group variable to the first column
  stats <- stats %>% dplyr::select(group, everything())
  
  colnames(stats)
  
  
  barplots <- lapply(names(Report[, sapply(Report, is.numeric)]), function(x) {
    y_label <- switch(x,
                      "Tailbase.raw.distance" = "Distance moved (cm)",
                      "Tailbase.speed.moving" = "Speed (cm/s)",
                      "Tailbase.distance.moving" = "Distance moving (cm)",
                      "Tailbase.time.moving" = "Time moving (s)",
                      "Tailbase.raw.speed" = "Raw speed (cm/s)",
                      "Tailbase.total.time" = "Total time (s)",
                      "Tailbase.time.stationary" = "Time not moving (s)",
                      "Tailbase.percentage.moving" = "% moving",
                      x)
    
    ggplot(Report, aes(x = group, y = .data[[x]], fill = "white", color = group)) +
      # Add bar for mean
      stat_summary(fun.data = function(y) {
        return(c(ymin = mean(y) - sd(y),
                 ymax = mean(y) + sd(y)))
      }, geom = "errorbar", position = position_dodge(0.6), width = 0.2) +  # Change from "linerange" to "errorbar" and add width argument
      stat_summary(fun = mean, geom = "bar", position = position_dodge(), width = 0.6) +
      geom_jitter(position = position_jitterdodge(jitter.width = 0.3), alpha = 0.4, size = 3) +
      scale_color_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
      scale_fill_manual(values = "white") +
      scale_y_continuous(expand = c(0, 0.8)) +  # Here we set the multiplicative constant to 0
      labs(x = "", y = y_label)
      # tryCatch({
      #   stat_compare_means(method = "t.test", label = "p.signif")
      # }, error = function(e) {
      #   geom_blank()  # return a blank geom if a t-test can't be performed
      # }) 
    # theme_minimal()
  })
  
  
  # Combine boxplots and barplots
  all_plots <- c(barplots)
  
  # Save all plots to a single PDF file
  g <- marrangeGrob(grobs = all_plots, nrow=3, ncol=2, top = NULL)
  ggsave("plots_2.pdf", g, width = 8.5, height = 11)
  
  # Return the transposed data frame and the plots
  return(list(Report = Report, stats = stats, barplots = barplots))
}

generate_additional_plots <- function(TrackingAll, groupName) {
  # Initialize a list to store the plots
  all_plots <- list()
  
  # Loop over each data frame in the list
  for (i in seq_along(TrackingAll)) {
    # Generate the plots
    zone_visits_plot <- PlotZoneVisits(TrackingAll[[i]], points = c("Head"))
    if (!is.null(zone_visits_plot) && inherits(zone_visits_plot, "gg")) {
      # Add a title with the group name and file number
      zone_visits_plot <- zone_visits_plot + ggtitle(paste(groupName, i))
      all_plots <- c(all_plots, list(zone_visits_plot))
    }
    
    density_paths_plots_2 <- PlotDensityPaths_2(TrackingAll[[i]], points = c("Head"))
    if (!is.null(density_paths_plots_2)) {
      # Add a title with the group name and file number
      density_paths_plots_2 <- lapply(density_paths_plots_2, function(plot) plot + ggtitle(paste(groupName, i)))
      all_plots <- c(all_plots, density_paths_plots_2)
    }
  }
  
  # Return the list of plots
  return(all_plots)
}

selected_points <- c("Head")  
selected_zones <- c("center", "periphery")

CalculateZoneVisits <- function(t, points, zones) {
  
  if(!IsTrackingData(t)){
    stop("Object is not of type TrackingData")
  }
  if(length(setdiff(points, names(t$data))) > 0){
    warning("invalid points")
    return(NULL)
  }
  if(length(setdiff(zones, names(t$zones))) > 0){
    warning("invalid zones")
    return(NULL)
  }
  
  dat <- NULL
  for(j in points){
    for(i in zones){
      in_zone <- IsInZone(t, j, i, t$zones.invert[[i]])
      print(paste("Length of in_zone for point", j, "and zone", i, ":", length(in_zone)))
      print(paste("Length of seconds:", length(t$seconds)))
      if (!is.null(t$file_name)) {
        file_name_vector <- rep(t$file_name, length(in_zone))
      } else {
        file_name_vector <- rep("Unknown file", length(in_zone))  # or choose a suitable replacement
      }
      dat <- rbind(dat, data.frame(file_name = file_name_vector,
                                   seconds = t$seconds[1:length(in_zone)],
                                   zone = ifelse(in_zone, i, NA),
                                   type = "automatic",
                                   point = j))
    }
  }
  
  return(dat)
}


# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
#   
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
#   
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
#   
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
#   
#   # Merge total_time_per_file (total number of frames) into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
#   
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
#   
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
#   
#   # Determine whether each file is from a control or a mutant
#   dat_summary$group <- ifelse(grepl("control", tolower(dat_summary$file_name)), "Control", "Mutant") #Change here for groupName.
#   
#   
#   # Filter data for 'center' and 'periphery'.
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
#   
#   # # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
# 
# # Perform t-tests
# t_test_results <- dat_summary_filtered %>%
#   split(.$zone) %>%
#   lapply(function(df) t.test(percentage ~ group, data = df))
# #
# # # Extract p-values from t-tests
# p_values <- sapply(t_test_results, function(t) t$p.value)
# #
# # # Calculate the maximum y-value for each zone
# max_y <- dat_summary_grouped %>%
#   group_by(zone) %>%
#   summarise(max_y = max(mean_percentage + sd_percentage))
# #
# # # Add a column of p-values to the max_y data frame
# max_y$p_values <- p_values[max_y$zone]
# 
# # Plot data
# p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#   geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#   geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                 width = 0.2, position = position_dodge(0.9)) +
#   scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#   # geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#   #           vjust = -0.5, hjust = 0.5, color = "black", size = 3, inherit.aes = FALSE) +
#   theme_bw() +
#   labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Point") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
# #
# # # Save plot to a PDF file
# ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
#   # 
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
# }

# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
#   
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
#   
#   # Assuming dat_combined is already a data frame, if not, convert it first.
#   dat_combined <- as.data.frame(dat_combined)
#   
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
#   
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
#   
#   # Merge total_time_per_file (total number of frames) into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
#   
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
#   
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
#   
#   # Add a groupName column to the summary data frame
#   dat_summary$group <- groupName
# 
#   
#   # Filter data for 'center' and 'periphery'.
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
#   
#   # # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
#   
#   # Perform t-tests
#   t_test_results <- dat_summary_filtered %>%
#     split(.$zone) %>%
#     lapply(function(df) t.test(percentage ~ group, data = df))
#   #
#   # # Extract p-values from t-tests
#   p_values <- sapply(t_test_results, function(t) t$p.value)
#   #
#   # # Calculate the maximum y-value for each zone
#   max_y <- dat_summary_grouped %>%
#     group_by(zone) %>%
#     summarise(max_y = max(mean_percentage + sd_percentage))
#   #
#   # # Add a column of p-values to the max_y data frame
#   max_y$p_values <- p_values[max_y$zone]
#   
#   # Plot data
#   p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) +
#     scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#     # geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#     #           vjust = -0.5, hjust = 0.5, color = "black", size = 3, inherit.aes = FALSE) +
#     theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Point") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   #
#   # # Save plot to a PDF file
#   ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
#   # 
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
# }


# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
#   
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
#   
#   # Assuming dat_combined is already a data frame, if not, convert it first.
#   dat_combined <- as.data.frame(dat_combined)
#   
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
#   
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
#   
#   # Merge total_time_per_file (total number of frames) into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
#   
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
#   
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
#   
#   # Add a groupName column to the summary data frame
#   dat_summary$group <- groupName
#   
#   
#   # Filter data for 'center' and 'periphery'.
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
#   
#   # # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
#   
#   
#   # Determine the unique groups
#   unique_groups <- unique(dat_summary$group)
#   
#   # Proceed with t-test only if there are exactly 2 unique groups
#   if(length(unique_groups) == 2) {
#     t_test_results <- dat_summary_filtered %>%
#       split(.$zone) %>%
#       lapply(function(df) t.test(percentage ~ group, data = df))
#     
#     # Extract p-values from t-tests
#     p_values <- sapply(t_test_results, function(t) t$p.value)
#     
#     # Add p-values to max_y
#     max_y$p_values <- p_values[max_y$zone]
#     
#     # Plot code with geom_text uncommented
#   } else {
#     # Skip t-test and geom_text part in the plot
#   # Plot data
#   p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) +
#     scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#     # geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#     #           vjust = -0.5, hjust = 0.5, color = "black", size = 3, inherit.aes = FALSE) +
#     theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Point") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   }
#   #
#   # # Save plot to a PDF file
#   ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
#   # 
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
# }

# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
#   
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
#   
#   # Convert to data frame if necessary
#   dat_combined <- as.data.frame(dat_combined)
#   
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
#   
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
#   
#   # Merge total_time_per_file into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
#   
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
#   
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
#   
#   # Add a groupName column to the summary data frame
#   dat_summary$group <- groupName
#   
#   # Filter data for 'center' and 'periphery'
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
#   
#   # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
#   
#   # Determine the unique groups
#   unique_groups <- unique(dat_summary$group)
#   
#   # Plotting data setup
#   p_values <- NULL
#   max_y <- dat_summary_grouped %>%
#     group_by(zone) %>%
#     summarise(max_y = max(mean_percentage + sd_percentage))
#   
#   # Perform t-test and adjust plot if there are exactly 2 unique groups
#   if(length(unique_groups) == 2) {
#     t_test_results <- dat_summary_filtered %>%
#       split(.$zone) %>%
#       lapply(function(df) t.test(percentage ~ group, data = df))
#     
#     p_values <- sapply(t_test_results, function(t) t$p.value)
#     max_y$p_values <- p_values[max_y$zone]
#   }
#   
#   # Plot data
#   p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) +
#     scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red"))
#   
#   # Conditionally add p-value annotations if t-test was performed
#   if(!is.null(p_values)) {
#     p_2 <- p_2 + geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#                            vjust = -0.5, hjust = 0.5, color = "black", size = 3)
#   }
#   
#   p_2 <- p_2 + theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   # Save plot to a PDF file
#   ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
#   
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
# }

#This one works:
analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
  # Calculate zone visits
  zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))

  # Combine all data frames into one
  dat_combined <- do.call(rbind, zone_summaries)

  # Convert to data frame if necessary
  dat_combined <- as.data.frame(dat_combined)

  # Extract the file name from the row names
  dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))

  # Count the number of frames for each combination of file_name, zone, and point
  dat_summary <- dat_combined %>%
    group_by(file_name, zone, point) %>%
    summarise(frames_in_zone = n(), .groups = "drop")

  # Merge total_time_per_file into dat_summary
  total_frames <- dat_summary %>%
    group_by(file_name) %>%
    summarise(total_frames = sum(frames_in_zone), .groups = "drop")

  # Merge total frames back to the summary data frame
  dat_summary <- merge(dat_summary, total_frames, by = "file_name")

  # Calculate percentage of frames in zone
  dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100

  # Add a groupName column to the summary data frame
  dat_summary$group <- groupName

  # Filter data for 'center' and 'periphery'
  dat_summary_filtered <- dat_summary %>%
    filter(zone %in% c('center', 'periphery'))

  # Calculate mean and standard deviation of percentages for each group, zone, and point
  dat_summary_grouped <- dat_summary_filtered %>%
    group_by(group, zone, point) %>%
    summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")

  # Determine the unique groups
  unique_groups <- unique(dat_summary$group)

  # Plotting data setup
  p_values <- NULL
  max_y <- dat_summary_grouped %>%
    group_by(zone) %>%
    summarise(max_y = max(mean_percentage + sd_percentage))

  # Perform t-test and adjust plot if there are exactly 2 unique groups
  if(length(unique_groups) == 2) {
    t_test_results <- dat_summary_filtered %>%
      split(.$zone) %>%
      lapply(function(df) t.test(percentage ~ group, data = df))

    p_values <- sapply(t_test_results, function(t) t$p.value)
    max_y$p_values <- p_values[max_y$zone]
  }

  # Plot data
  p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
    geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
    geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
                  width = 0.2, position = position_dodge(0.9)) +
    scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red"))


  # Conditionally add p-value annotations if t-test was performed
  if(!is.null(p_values)) {
    p_2 <- p_2 + geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
                           vjust = -0.5, hjust = 0.5, color = "black", size = 3)
  }

  p_2 <- p_2 + theme_bw() +
    labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save plot to a PDF file
  ggsave("p_2.pdf", p_2, width = 8.5, height = 11)

  # Return summary data and plot
  return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
}

# selected_points <- c("Head")  
# selected_zones <- c("center", "periphery")

# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
#   
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
#   
#   # Convert to data frame if necessary
#   dat_combined <- as.data.frame(dat_combined)
#   
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
#   
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
#   
#   # Merge total_time_per_file into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
#   
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
#   
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
#   
#   # Add a groupName column to the summary data frame
#   dat_summary$group <- groupName
#   
#   # Filter data for 'center' and 'periphery'
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
#   
#   # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
#   
#   # Determine the unique groups
#   unique_groups <- unique(dat_summary$group)
#   
#   # Plotting data setup
#   p_values <- NULL
#   max_y <- dat_summary_grouped %>%
#     group_by(zone) %>%
#     summarise(max_y = max(mean_percentage + sd_percentage))
#   
#   # Perform t-test and adjust plot if there are exactly 2 unique groups
#   if(length(unique_groups) == 2) {
#     t_test_results <- dat_summary_filtered %>%
#       split(.$zone) %>%
#       lapply(function(df) t.test(percentage ~ group, data = df))
#     
#     p_values <- sapply(t_test_results, function(t) t$p.value)
#     max_y$p_values <- p_values[max_y$zone]
#   }
#   
#   # Plot data
#   p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) 
#     # scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red"))
#   
#   # Conditionally add p-value annotations if t-test was performed
#   if(!is.null(p_values)) {
#     p_2 <- p_2 + geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#                            vjust = -0.5, hjust = 0.5, color = "black", size = 3)
#   }
#   
#   p_2 <- p_2 + theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   # Save plot to a PDF file
#   ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
#   
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_2))
# }



# analyze_tracking_data <- function(TrackingAll, selected_points, selected_zones, groupName) {
#   # Calculate zone visits
#   zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
# 
#   # Combine all data frames into one
#   dat_combined <- do.call(rbind, zone_summaries)
# 
#   # Convert to data frame if necessary
#   dat_combined <- as.data.frame(dat_combined)
# 
#   # Extract the file name from the row names
#   dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
# 
#   # Count the number of frames for each combination of file_name, zone, and point
#   dat_summary <- dat_combined %>%
#     group_by(file_name, zone, point) %>%
#     summarise(frames_in_zone = n(), .groups = "drop")
# 
#   # Merge total_time_per_file into dat_summary
#   total_frames <- dat_summary %>%
#     group_by(file_name) %>%
#     summarise(total_frames = sum(frames_in_zone), .groups = "drop")
# 
#   # Merge total frames back to the summary data frame
#   dat_summary <- merge(dat_summary, total_frames, by = "file_name")
# 
#   # Calculate percentage of frames in zone
#   dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
# 
#   # Add a groupName column to the summary data frame
#   dat_summary$group <- groupName
# 
#   # Filter data for 'center' and 'periphery'
#   dat_summary_filtered <- dat_summary %>%
#     filter(zone %in% c('center', 'periphery'))
# 
#   # Calculate mean and standard deviation of percentages for each group, zone, and point
#   dat_summary_grouped <- dat_summary_filtered %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
# 
#   # Determine the unique groups
#   unique_groups <- unique(dat_summary$group)
# 
#   # Plotting data setup
#   p_values <- NULL
#   max_y <- dat_summary_grouped %>%
#     group_by(zone) %>%
#     summarise(max_y = max(mean_percentage + sd_percentage))
# 
#   # # Perform t-test and adjust plot if there are exactly 2 unique groups
#   # if(length(unique_groups) == 2) {
#   #   t_test_results <- dat_summary_filtered %>%
#   #     split(.$zone) %>%
#   #     lapply(function(df) t.test(percentage ~ group, data = df))
#   #
#   #   p_values <- sapply(t_test_results, function(t) t$p.value)
#   #   max_y$p_values <- p_values[max_y$zone]
#   # }
#   #
#   # # Plot data
#   # p_2 <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#   #   geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#   #   geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#   #                 width = 0.2, position = position_dodge(0.9)) +
#   #   scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red"))
#   #
#   # # Conditionally add p-value annotations if t-test was performed
#   # if(!is.null(p_values)) {
#   #   p_2 <- p_2 + geom_text(data = max_y, aes(x = zone, y = max_y, label = paste0('p = ', round(p_values, 10))),
#   #                          vjust = -0.5, hjust = 0.5, color = "black", size = 3)
#   # }
#   #
#   # p_2 <- p_2 + theme_bw() +
#   #   labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
#   #   theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   #
#   # # Save plot to a PDF file
#   # ggsave("p_2.pdf", p_2, width = 8.5, height = 11)
# 
#   # Perform t-tests between groups for each zone
#   t_test_results <- dat_summary_grouped %>%
#     split(.$zone) %>%
#     lapply(function(df) t.test(percentage ~ group, data = df))
# 
#   p_values <- sapply(t_test_results, function(t) t$p.value)
#   max_y <- max(dat_summary_grouped$mean_percentage + dat_summary_grouped$sd_percentage, na.rm = TRUE)
# 
#   # Plot data
#   p_combined <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) +
#     geom_text(aes(x = zone, y = max_y, label = sprintf("p=%.3f", p_values)),
#               position = position_dodge(0.9), vjust = -0.5) +
#     scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#     theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
# 
#   # Save plot to a PDF file
#   ggsave("combined_analysis_plot.pdf", p_combined, width = 8.5, height = 11)
# 
# 
#   # Return summary data and plot
#   return(list(summary = dat_summary_filtered, dat_summary_grouped, plot = p_combined))
# }

# analyze_tracking_data <- function(all_zone_data, selected_points, selected_zones) {
#   # Combine data from all groups
#   combined_dat <- do.call(rbind, all_zone_data)
#   
#   # Calculate mean and standard deviation for each group, zone, and point
#   dat_summary_grouped <- combined_dat %>%
#     group_by(group, zone, point) %>%
#     summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
#   
#   # Perform t-tests between groups for each zone
#   t_test_results <- dat_summary_grouped %>%
#     split(.$zone) %>%
#     lapply(function(df) t.test(percentage ~ group, data = df))
#   
#   p_values <- sapply(t_test_results, function(t) t$p.value)
#   max_y <- max(dat_summary_grouped$mean_percentage + dat_summary_grouped$sd_percentage, na.rm = TRUE)
#   
#   # Plot data
#   p_combined <- ggplot(dat_summary_grouped, aes(x = zone, y = mean_percentage, fill = group)) +
#     geom_bar(stat = "identity", position = position_dodge(), colour = "black") +
#     geom_errorbar(aes(ymin = mean_percentage - sd_percentage, ymax = mean_percentage + sd_percentage),
#                   width = 0.2, position = position_dodge(0.9)) +
#     geom_text(aes(x = zone, y = max_y, label = sprintf("p=%.3f", p_values)), 
#               position = position_dodge(0.9), vjust = -0.5) +
#     scale_fill_manual(values = c("Control" = "dodgerblue", "Mutant" = "red")) +
#     theme_bw() +
#     labs(x = "Zone", y = "Mean Percentage of Frames (%)", fill = "Group") +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   # Save plot to a PDF file
#   ggsave("combined_analysis_plot.pdf", p_combined, width = 8.5, height = 11)
#   
#   # Return the plot
#   return(p_combined)
# }



# generate_additional_plots <- function(TrackingAll) {
#   # Initialize a list to store the plots
#   all_plots <- list()
#   
#   # Loop over each data frame in the list
#   for (name in names(TrackingAll)) {
#     # Generate the plots
#     # zone_plot <- PlotZones(TrackingAll[[name]])
#     # if (!is.null(zone_plot) && inherits(zone_plot, "gg")) {
#     #   all_plots <- c(all_plots, list(zone_plot))
#     # }
#     
#     # density_paths_plots <- PlotDensityPaths(TrackingAll[[name]], points = c("Head"))
#     # if (!is.null(density_paths_plots)) {
#     #   all_plots <- c(all_plots, density_paths_plots)
#     # }
#     
#     zone_visits_plot <- PlotZoneVisits(TrackingAll[[name]], points = c("Head"))
#     if (!is.null(zone_visits_plot) && inherits(zone_visits_plot, "gg")) {
#       all_plots <- c(all_plots, list(zone_visits_plot))
#     }
#     
#     density_paths_plots_2 <- PlotDensityPaths_2(TrackingAll[[name]], points = c("Head"))
#     if (!is.null(density_paths_plots_2)) {
#       all_plots <- c(all_plots, density_paths_plots_2)
#     }
#   }
#   
#   # Save all plots to a single PDF file
#   pdf("additional_plots.pdf", width = 8.5, height = 11)
#   for (i in seq(1, length(all_plots), by = 6)) {
#     grid.arrange(grobs = all_plots[i:min(i + 5, length(all_plots))], ncol = 2)
#   }
#   dev.off()
#   
#   # Return the list of plots
#   return(all_plots)
# }

calculate_paw_distance <- function(Tracking) {
  #1) Creating a list of dataframes for the front paws and back paws:
  df_F_paw <- list(RF_paw = Tracking$data$RF_paw, LF_paw = Tracking$data$LF_paw)
  df_B_paw <- list(RB_paw = Tracking$data$RB_paw, LB_paw = Tracking$data$LB_paw)
  
  #2) In both dataframes, we select the frames in which the speed is >0.05:
  filtered_df_F_paw <- map(df_F_paw, ~filter(.x, speed > 0.05))
  filtered_df_B_paw <- map(df_B_paw, ~filter(.x, speed > 0.05))
  
  #3) We select the same frames in which both dataframes:
  RF_paw <- filtered_df_F_paw$RF_paw[filtered_df_F_paw$RF_paw$frame %in% filtered_df_F_paw$LF_paw$frame == "TRUE",]
  LF_paw <- filtered_df_F_paw$LF_paw[filtered_df_F_paw$LF_paw$frame %in% filtered_df_F_paw$RF_paw$frame == "TRUE",]
  
  RB_paw <- filtered_df_B_paw$RB_paw[filtered_df_B_paw$RB_paw$frame %in% filtered_df_B_paw$LB_paw$frame == "TRUE",]
  LB_paw <- filtered_df_B_paw$LB_paw[filtered_df_B_paw$LB_paw$frame %in% filtered_df_B_paw$RB_paw$frame == "TRUE",]
  
  #4) Now, we calculate the distance between front paws and back paws:
  Front_paw_distance <- Distance2d(RF_paw, LF_paw)
  Back_paw_distance <- Distance2d(RB_paw, LB_paw)
  
  # Return a list with the mean and sd of the distances
  return(list(
    Front_paw_distance_mean = mean(Front_paw_distance),
    Front_paw_distance_sd = sd(Front_paw_distance),
    Back_paw_distance_mean = mean(Back_paw_distance),
    Back_paw_distance_sd = sd(Back_paw_distance)
  ))
}

# Define the function to calculate stride length:
calculate_stride_length <- function(Tracking){
  # Validate that both dataframes have the same number of rows
  if (nrow(Tracking$data$LF_paw) != nrow(Tracking$data$LB_paw)) {
    stop("The dataframes for LF_paw and LB_paw must have the same number of rows.")
  }
  
  # Filter dataframes based on speed threshold
  filtered_LF_paw <- filter(Tracking$data$LF_paw, speed > 0.05)
  filtered_LB_paw <- filter(Tracking$data$LB_paw, speed > 0.05)
  
  # Select the common frames for both filtered paws
  common_frames <- intersect(filtered_LF_paw$frame, filtered_LB_paw$frame)
  
  LF_paw <- filtered_LF_paw[filtered_LF_paw$frame %in% common_frames,]
  LB_paw <- filtered_LB_paw[filtered_LB_paw$frame %in% common_frames,]
  
  # Calculate the differences between x and y coordinates of LF_paw and LB_paw
  dx <- LF_paw$x - LB_paw$x
  dy <- LF_paw$y - LB_paw$y
  
  # Calculate the stride length as the Euclidean distance
  stride_length <- sqrt(dx^2 + dy^2)
  
  # Return mean and standard deviation of the stride length
  return(list(
    mean_stride_length = mean(stride_length, na.rm = TRUE),
    sd_stride_length = sd(stride_length, na.rm = TRUE)
  ))
}


calculate_step_width <- function(Tracking) {
  #1) We filter the Tracking data by speed, such that we select moments when the animal is walking:
  filtered_speed <- map(Tracking$data, ~filter(.x, speed >0.05))
  
  #2) We are going to select the frames shared by all paws:
  list_paws <- list(RF = filtered_speed$RF_paw, LF = filtered_speed$LF_paw, RB = filtered_speed$RB_paw, LB = filtered_speed$LB_paw)
  
  #2.1) Select the common frames:
  common_frames <- Reduce(intersect, lapply(list_paws, `[[`, "frame"))
  
  #2.2) Filter all dataframes from the list with the selected frames:
  filtered_df_list <- lapply(list_paws, function(df) subset(df, frame %in% common_frames))
  
  #3) Create a rectangle between the four points 
  
  # 3.1) Combine the data frames into a single data frame
  combined_df <- full_join(
    filtered_df_list$RF, filtered_df_list$LF, by = "frame", suffix = c("_RF", "_LF")
  ) %>%
    full_join(
      filtered_df_list$RB, by = "frame"
    ) %>%
    full_join(
      filtered_df_list$LB, by = "frame", suffix = c("_RB", "_LB")
    )
  
  # 3.2) We are going to create two functions:
  # 3.2.1) To calculate the distance between a point p and a line segment a-b
  distPointSegment <- function(p, a, b) {
    v <- b - a
    w <- p - a
    c1 <- sum(w*v)
    if (c1 <= 0)
      return(sqrt(sum((p - a)^2)))
    c2 <- sum(v*v)
    if (c2 <= c1)
      return(sqrt(sum((p - b)^2)))
    b <- c1/c2
    pb <- a + b * v
    return(sqrt(sum((p - pb)^2)))
  }
  
  # 3.2.2) We will create a function to calculate the average distance between the two longer sides of a rectangle for a given frame:
  calcAvgDist <- function(frame) {
    RF <- c(frame$x_RF, frame$y_RF)
    LF <- c(frame$x_LF, frame$y_LF)
    RB <- c(frame$x_RB, frame$y_RB)
    LB <- c(frame$x_LB, frame$y_LB)
    
    dist1 <- distPointSegment(RF, LF, LB)
    dist2 <- distPointSegment(LF, RB, LB)
    dist3 <- distPointSegment(RB, RF, RB)
    dist4 <- distPointSegment(LB, RF, LF)
    
    # Here, we assume the two longer sides of the rectangle are opposite each other. Thus, the average distance between the longer sides is the average of the two smallest distances.
    avgDist <- mean(sort(c(dist1, dist2, dist3, dist4), decreasing = FALSE)[1:2])
    
    return(avgDist)
  }
  
  combined_df <- combined_df %>%
    rowwise() %>%
    mutate(avgDist = calcAvgDist(cur_data()))
  
  # Return the mean of the average distances
  return(mean(combined_df$avgDist))
}

# 05/26/25 Alyssa -------------------------------------------------------------------------------------------------
# function to calculate p-value or adj_p value
calculate_p_value <- function(data, column, group) {
  groups <- unique(data[[group]])
  n_groups <- length(groups)
  
  if (any(table(data[[group]]) < 3)) {
    return(NULL)
  }
  
  if (n_groups == 2) {
    # perform t-test for 2 groups
    test_result <- t.test(data[[column]] ~ data[[group]])
    p_value <- test_result$p.value
    return(paste("p = ", round(p_value, 3)))
  } else if (n_groups > 2) {
    # perform ANOVA for 3+ groups
    anova_result <- aov(data[[column]] ~ data[[group]])
    p_value <- summary(anova_result)[[1]]$`Pr(>F)`[1]
    adj_p_value <- p.adjust(p_value, method = "bonferroni")
    return(paste("adj_p = ", round(p_value, 3)))
  } else {
    return(NULL)
  }
}


# create boxplot function
create_boxplot <- function(data, column, group, y_label, source_id = NULL) {
  
  # calculate p-value or adjusted p-value
  annotation_text <- calculate_p_value(data, column, group)
  
  # create the boxplot
  bp <- plot_ly(
    data = data,
    x = data[[group]],
    y = data[[column]],
    type = "box",
    boxpoints = "all", # show all points (similar to geom_jitter)
    jitter = 0.3, # Jitter width
    pointpos = 0,
    marker = list(size = 5, # Point size
                  line = list(color = "black", width = 1)), # Point transparency (alpha)
    source = source_id
  ) %>%
    layout(
      xaxis = list(title = "", showline = TRUE, linecolor = "grey"), # empty x-axis label
      yaxis = list(title = y_label, showline = TRUE, linecolor = "grey"), # set y-axis label
      showlegend = FALSE # remove the legend
    ) %>%
    config(
      modeBarButtonsToAdd = list('drawline','drawopenpath','drawclosedpath',
                                 'drawcircle','drawrect','eraseshape')
    )
  
  # add annotation if p-value of adjusted p-value is available
  if (!is.null(annotation_text)) {
    bp <- bp %>%
      add_annotations(
        x = 0.5, # position annotation at the middle
        y = max(data[[column]] * 1.1, na.rm = TRUE),
        text = annotation_text,
        showarrow = FALSE,
        font = list(size = 14)
      )
  }
  
  return(bp)
}


# density path
PlotlyDensity <- function(t, points = "Head", SDcutoff = 4, title = "Density Path") {
  if(!IsTrackingData(t)) stop("Invalid TrackingData")
  
  out <- list()
  
  SDPlot <- function(x, nSD) {
    ifelse((mean(x) - x) / sd(x) > -nSD, x, mean(x) + nSD * sd(x))
  }
  
  for(i in points) {
    data_plot <- t$data[[i]]
    xbreaks <- seq(floor(min(data_plot$x)), ceiling(max(data_plot$x)), by = 0.1)
    ybreaks <- seq(floor(min(data_plot$y)), ceiling(max(data_plot$y)), by = 0.1)
    data_plot$latbin <- xbreaks[cut(data_plot$x, breaks = xbreaks, labels=F)]
    data_plot$longbin <- ybreaks[cut(data_plot$y, breaks = ybreaks, labels=F)]
    
    p <- ggplot(data = data_plot, aes(x, y)) + 
      stat_density_2d(aes(latbin, longbin, fill=..density..),
                      geom = 'raster', contour = FALSE) +
      scale_fill_gradientn(colors = c("blue", "orange"), name="Density") +
      geom_path(aes(color = SDPlot((speed * t$fps), SDcutoff)),
                size = 0.3, alpha = 1) +
      ggtitle(paste(i, title)) +
      scale_color_gradient2(name = paste("speed (",t$distance.units,"/s)", sep = ""),
                            high = "red", low = "#FFF59D", mid = '#FAFAFA') +
      theme_bw()
    
    # convert to plotly and store
    out[[i]] <- ggplotly(p) %>%
      layout(hovermode = "closest",
             margin = list(l = 50, r = 50, b = 50, t = 50))
  }
  return(out)
}

generate_density_plots <- function(tracking_list, group_name) {
  lapply(seq_along(tracking_list), function(i) {
    plots <- PlotlyDensity(tracking_list[[i]], points = "Head",
                           title = paste0("Group_", group_name, "_File_", i))
    plots[["Head"]] 
  }) %>%
    setNames(paste0("density_", seq_along(tracking_list)))
}


# AW ------------------------------------------------------------------------------------------------------------------------------
#' calculate physical body measurements
#' 
#' @param TrackingAll Named list of animal tracking datasets
#' @return a dataframe with columns: name | group_type | group | area | length | step_width | front_paw_distance_mean | front_paw_distance_sd
#' | back_paw_distance_mean | back_paw_distance_sd | mean_stride_length | sd_stride_length

calculate_body_metrics <- function(TrackingAll) {
  
  # Initialize vectors to store the results
  body_metrics <- data.frame(
    name = character(length(TrackingAll)),
    group = character(length(TrackingAll)),
    area = numeric(length(TrackingAll)),
    length = numeric(length(TrackingAll)),
    step_width = numeric(length(TrackingAll)),
    front_paw_distance_mean = numeric(length(TrackingAll)),
    front_paw_distance_sd = numeric(length(TrackingAll)),
    back_paw_distance_mean = numeric(length(TrackingAll)),
    back_paw_distance_sd = numeric(length(TrackingAll)),
    mean_stride_length = numeric(length(TrackingAll)),
    sd_stride_length = numeric(length(TrackingAll)),
    stringsAsFactors = FALSE
  )
  
  # loop over each data frame
  for (i in seq_along(TrackingAll)) {
    # store name and group_type in dataframe
    body_metrics$name <- names(TrackingAll)
#    body_metrics$group_type[i] <- ifelse(grepl("control", body_metrics$name[i], ignore.case = TRUE), "Control", "Mutant")
    
    # Apply MedianMouseArea and store the result. 
    # Here, we are not filtering for the speed. 
    # We calculate the average area in the entire video. 
    body_metrics$area[i] <- MedianMouseArea(TrackingAll[[i]], points = c("Snout", "Head", "Tailbase", "RF_paw",
                                                                         "LF_paw", "RB_paw", "LB_paw"))
    
    # Apply MedianMouseLength and store the result. Here, we are not filtering for the speed. 
    body_metrics$length[i] <- MedianMouseLength(TrackingAll[[i]], front = "Snout", back = "Tailbase")
    
    # Apply calculate_step_width and store the result
    body_metrics$step_width[i] <- calculate_step_width(TrackingAll[[i]])
    
    # Apply calculate_paw_distance and store the result. 
    # This function filters for moments in which the animal is walking with a speed threshold of >0.05 (at P15)
    paw_distance <- calculate_paw_distance(TrackingAll[[i]])
    body_metrics$front_paw_distance_mean[i] <- paw_distance$Front_paw_distance_mean
    body_metrics$front_paw_distance_sd[i] <- paw_distance$Front_paw_distance_sd
    body_metrics$back_paw_distance_mean[i] <- paw_distance$Back_paw_distance_mean
    body_metrics$back_paw_distance_sd[i] <- paw_distance$Back_paw_distance_sd
    
    # Apply calculate_stride_length and store the result
    stride_lengths <- calculate_stride_length(TrackingAll[[i]])
    body_metrics$mean_stride_length[i] <- stride_lengths$mean_stride_length
    body_metrics$sd_stride_length[i] <- stride_lengths$sd_stride_length
  }
  return(body_metrics)
}

#' function to calculate p-value or adj_p value
#' 
calculate_p_value <- function(data, column, group) {
  groups <- unique(data[[group]])
  n_groups <- length(groups)
  
  if (any(table(data[[group]]) < 3)) {
    return(NULL)
  }
  
  if (n_groups == 2) {
    # perform t-test for 2 groups
    test_result <- t.test(data[[column]] ~ data[[group]])
    p_value <- test_result$p.value
    return(paste("p_val = ", round(p_value, 3)))
  } else if (n_groups > 2) {
    # perform ANOVA for 3+ groups
    anova_result <- aov(data[[column]] ~ data[[group]])
    p_value <- summary(anova_result)[[1]]$`Pr(>F)`[1]
    adj_p_value <- p.adjust(p_value, method = "bonferroni")
    return(paste("adj_p = ", round(p_value, 3)))
  } else {
    return(NULL)
  }
}

#' generate boxplots for all numeric column
#' 
#' @param data dataframe containing metrics and grouping variables
#' @param group name of column defining experimental groups
#' @param group_type name of colum defining control/mutant
#' @param p_value_func function to calculate p-value
#' @return a cowplot grid of ggplot objects
create_static_boxplot <- function(data, group = "group", 
                                  p_value_func = calculate_p_value,
                                  y_label_map = NULL,
                                  fill_colors) {
  
  # get numeric colums excluding variablitly measures
  numeric_cols <- names(data)[sapply(data, is.numeric)]
  numeric_cols <- numeric_cols[!grepl("_sd|_sem|sd_", numeric_cols)]
  
  boxplots <- lapply(numeric_cols, function(col) {
    
    # calculate p-value
    p_value <- p_value_func(data, col, group)
    
    # use custom label if provide and col exists in the map; otherwise, keep col
    y_label <- if (!is.null(y_label_map) && col %in% names(y_label_map)) {
      y_label_map[[col]]
    } else {
      col
    }
    
    p <- ggplot(data, aes(x = .data[[group]], y = .data[[col]], fill = .data[[group]])) +
      geom_boxplot(
        colour = "gray40" # hide default outliers
      ) + 
      scale_fill_manual(values = fill_colors) +
      labs(x = "",
           y = y_label,
           title = p_value) +
      theme_minimal() +
      theme(plot.title = element_text(hjust = 0, size = 11),
            axis.line.x = element_line(size = 0.5, color = "darkgrey"),
            axis.line.y = element_line(size = 0.5, color = "darkgrey"),
            legend.position = "none")
    
    # Add jitter points with consistent color
    p <- p + geom_jitter(color = '#97a6c4', width = 0.2, size = 1)
    
    return(p)
  })
  return(boxplots)
}


# list to modify y_label
BodyMetrics_y_label <- list(
  area = "mouse area (cm)",
  length = "mouse length (cm)",
  front_paw_distance_mean = "Front paw distance (cm)",
  back_paw_distance_mean = "Back paw distance (cm)",
  mean_stride_length = "Stride length (cm)",
  Stride_length_left_mean = "Stride length left (cm)",
  step_width = "Step width (cm)"
)


# list to modify y_label
movement_y_label <- list(
  "Tailbase.raw.distance" = "Distance moved (cm)",
  "Tailbase.speed.moving" = "Speed (cm/s)",
  "Tailbase.distance.moving" = "Distance moving (cm)",
  "Tailbase.time.moving" = "Time moving (s)",
  "Tailbase.raw.speed" = "Raw speed (cm/s)",
  "Tailbase.total.time" = "Total time (s)",
  "Tailbase.time.stationary" = "Time not moving (s)",
  "Tailbase.percentage.moving" = "% moving"
)

#' function to convert ggplot boxplots to Plotly and renders them in shiny
#' 
#' @param boxplots list of ggplot objects (from create_static_boxplot)
#' @param output_id_prefix character prefix for shiny output IDs
#' @return invisible NULL, creates shiny output elements
render_boxplots_interactive <- function(boxplots, output_id_prefix = "plotly",
                                        session = shiny::getDefaultReactiveDomain()) {

  lapply(seq_along(boxplots), function(i) {
    output_name <- paste0(output_id_prefix, i) # used by shiny to display the plot
    source_id <- paste0(i, output_id_prefix)
    session$output[[output_name]] <- renderPlotly({
      p <- ggplotly(boxplots[[i]], tooltip = "text", source =  source_id) %>% # source_name for event trigger
        layout(
          margin = list(l = 50, r = 50, b = 50, t = 50),
          showlegend = FALSE
        ) %>%
        config(displayModeBar = TRUE) 
    }) 
    
    observeEvent(plotly::event_data("plotly_click", source = source_id), {
      showModal(modalDialog(
        title = boxplots[[i]]$label,
        size = "xl",
        easyClose = TRUE,
        renderPlotly({
          p <- ggplotly(boxplots[[i]]) %>%
            layout(margin = list(l = 50, r = 50, b = 50, t = 50), showlegend = FALSE) %>%
            config(displayModeBar = TRUE)
        })
      ))
    })
  })
  invisible(NULL)
}

#render_boxplots_interactive <- function(boxplots, output_id_prefix = "bodyMetrics_plotly",
#                                        session = shiny::getDefaultReactiveDomain()) {
#  lapply(seq_along(boxplots), function(i) {
#    output_name <- paste0(output_id_prefix, i)
#    session$output[[output_name]] <- renderPlotly({
#      ggplotly(boxplots[[i]], tooltip = "text") %>%
#        layout(
#          margin = list(l = 50, r = 50, b = 50, t = 50),
#          showlegend = FALSE
#        ) %>%
#        config(displayModeBar = TRUE)
#    }) 
#  })
#  invisible(NULL)
#}

#' generate PDF report of Boxplots
#' creates a PDF document with boxplots (maximum 6 per page)
#' 
#' @param boxplots list of ggplot objects (from create_static_boxplot)
#' @param filename  character string for output file path
#' @param ncol number of columns per page (default 2)
#' @param nrow number of rows per page (default 3)
#' 
#' @return generate a pdf file, returns invisible NULL
save_boxplots_to_pdf <- function(plot_list, file_path, title = "Boxplots") {
  pdf(file = file_path, width = 8.5, height = 11) # US letter size
  on.exit(dev.off())
  
  n_per_page <- 6
  n_cols <- 2
  n_plots <- length(plot_list)
  pages <- ceiling(n_plots / n_per_page)
  
  for (i in seq_len(pages)) {
    start <- (i-1) * n_per_page + 1
    end <- min(i * n_per_page, n_plots)
    plots_this_page <- plot_list[start:end]
    
    # pad with null grobs to preserve layout
    n_missing <-  n_per_page - length(plots_this_page)
    if (n_missing > 0) {
      plots_this_page <- c(plots_this_page, rep(list(nullGrob()), n_missing))
    }
    
    # main grid of plots
    plot_grid <- arrangeGrob(grobs = plots_this_page, ncol = n_cols)
    
    # title (at top)
    title_grob <- textGrob(title, gp = gpar(fontsize = 16, fontface = "bold"))
    
    # Footer (page number)
    footer_grob <- textGrob(
      label = paste("----- Page", i, "of", pages, "-----"),
      gp = gpar(fontsize = 10, col = "grey40"),
      just = "center"
    )
    
    # combine all
    full_page <- arrangeGrob(
      title_grob,
      plot_grid,
      footer_grob,
      ncol = 1,
      heights = unit(c(1, 9, 0.5), "in"), # top, middle, bottom margins
      padding = unit(0.5, "in")
    )
    if (i > 1) grid.newpage()
    grid.draw(full_page)
  }
}

#' process raw movement tracking data
#' 
#' @param TrackingAll a list object containing raw tracking data
#' @return a tidy dataframe  
calculate_movement <- function(TrackingAll) {
  raw_report <- tryCatch(
    MultiFileReport(TrackingAll),
    error = function(e) {
      stop("Failed to generate MultFileReport: ", e$message, call. = FALSE)
    }
  )
  raw_report <- as.data.frame(raw_report[,1:9])
  raw_report$file <- names(TrackingAll)

  return(raw_report)
}

#' Plot Time Spent in Zones for Tracked Points
#'
#' Generates a list of ggplot objects showing when tracked body points
#' (e.g. "Head") were located in defined behavioral zones over time.
#' Each segment represents a frame during which the point was inside a zone.
#'
#' @param TrackingAll A list of TrackingData objects.
#' @param groupName A vector of group names matching the subjects in TrackingAll.
#' @param pts A character vector of point names to analyze (default = "Head").
#' @return A list of ggplot objects, one per TrackingData subject.
#' @import ggplot2
#' @export
#' 
plot_time_in_zones <- function(TrackingAll, groupName, pts = "Head", colors = NULL) {
  
  plots <- list()  # Initialize output list of plots
  
  for (i in seq_along(TrackingAll)) {
    track <- TrackingAll[[i]]  # Get current subject
    
    # 1. Validate required data
    if (!IsTrackingData(track)) {
      warning(paste("Entry", i, "is not valid TrackingData"))
      next
    }
    
    if (is.null(track$zones) || is.null(track$data$Head) || is.null(track$seconds)) {
      warning(paste("Missing data in entry", i))
      next
    }
    
    n_frames <- length(track$seconds)
    full_df <- data.frame()
    
    for (pt in pts) {
      pt_data <- track$data[[pt]]
      if (!is.data.frame(pt_data) || !all(c("x", "y") %in% names(pt_data))) {
        warning(paste("Invalid point:", pt, "in entry", i))
        next
      }
      
      zone_labels <- rep(NA_character_, n_frames)  # Empty vector to store zone assignments
      for (z_name in names(track$zones)) {
        zone_df <- track$zones[[z_name]]  # Get coordinates of the zone
        if (!all(c("x", "y") %in% names(zone_df))) {
          warning(paste("Invalid zone format in", z_name, "entry", i))
          next
        }
        inside <- point.in.polygon(
          pt_data$x, pt_data$y,  # Track points
          zone_df$x, zone_df$y           # Zone polygon
        )
        zone_labels[inside > 0] <- z_name  # Label frames that are inside
      }
      # 4. Create data frame for ggplot input
      df <- data.frame(
        Time_begin = track$seconds,
        Time_end = lead(track$seconds),
        Zone = factor(zone_labels, levels = names(track$zones)),
        Point = pt
      )
      
      full_df <- rbind(full_df, df)
    }
    
    full_df <- full_df[!is.na(df$Zone), ]  # Keep only points that fall into some zone
    full_df$Zone <- factor(full_df$Zone, levels = names(track$zones))
    
    # compute percentage time per zone
    zone_time <- full_df |>
      dplyr::mutate(duration = Time_end - Time_begin) |>
      dplyr::group_by(Zone) |>
      dplyr::summarise(total = sum(duration, na.rm = TRUE)) |>
      dplyr::mutate(percent = total / sum(total) * 100)
    
    # create new zone labels: "zone (xx.x%)"
    zone_labels <- zone_time %>%
      {setNames(
        sprintf("%s\n(%.1f%%)", .$Zone, .$percent), # Format: "zone\n(XX.X%)" 
        .$Zone #original zone names as keys
      )}
    full_df <- full_df %>%
      mutate(
        zone_label = map_chr(Zone, ~zone_labels[.x]) # Replace Zone with formatted labels
      )
    
    
    # 5. Generate and store plot
    p <- ggplot(na.omit(full_df), aes(x = Time_begin, xend = Time_end, y = Zone, color = Zone)) +
      geom_segment(size = 15) +
      facet_wrap(~Point, ncol = 1) +
      scale_y_discrete(labels = zone_labels) +
      scale_color_manual(values = colors) +
      theme_minimal() + 
      labs(
        title = paste(groupName, " ", i),
        x = "Time (seconds)",
        y = "Zone"
      ) +
      theme(plot.title = element_text(hjust = 0), # left-align title
            axis.line = element_line(color = "black"),
            axis.ticks = element_line(color = "black"),
            axis.text = element_text(color = "black"),
            axis.title = element_text(color = "black"),
            legend.position = "none",
            axis.text.y = element_text(size = 12),
            axis.title.x = element_text(size = 14),
            axis.title.y = element_text(size = 14),
            strip.text = element_text(size = 12)
      )
    
    plots[[i]] <- p
    
    
  }
  
  return(plots)
}


analyze_tracking <- function(TrackingAll, selected_points, selected_zones, groupName) {
  # Calculate zone visits
  zone_summaries <- lapply(TrackingAll, function(t) CalculateZoneVisits(t, points = selected_points, zones = selected_zones))
  
  # Combine all data frames into one
  dat_combined <- do.call(rbind, zone_summaries)
  
  # Convert to data frame if necessary
  dat_combined <- as.data.frame(dat_combined)
  
  # Extract the file name from the row names
  dat_combined$file_name <- sub("\\..*", "", rownames(dat_combined))
  
  # Count the number of frames for each combination of file_name, zone, and point
  dat_summary <- dat_combined %>%
    group_by(file_name, zone, point) %>%
    summarise(frames_in_zone = n(), .groups = "drop")
  
  # Merge total_time_per_file into dat_summary
  total_frames <- dat_summary %>%
    group_by(file_name) %>%
    summarise(total_frames = sum(frames_in_zone), .groups = "drop")
  
  # Merge total frames back to the summary data frame
  dat_summary <- merge(dat_summary, total_frames, by = "file_name")
  
  # Calculate percentage of frames in zone
  dat_summary$percentage <- dat_summary$frames_in_zone / dat_summary$total_frames * 100
  
  # Add a groupName column to the summary data frame
  dat_summary$group <- groupName
  
  # Filter data for 'center' and 'periphery'
  dat_summary_filtered <- dat_summary %>%
    filter(zone %in% c('center', 'periphery'))
  
  # Calculate mean and standard deviation of percentages for each group, zone, and point
  dat_summary_grouped <- dat_summary_filtered %>%
    group_by(group, zone, point) %>%
    summarise(mean_percentage = mean(percentage), sd_percentage = sd(percentage), .groups = "drop")
  
  # Determine the unique groups
  unique_groups <- unique(dat_summary$group)
  
  # Return summary data
  return(list(summary = dat_summary_filtered, dat_summary_grouped))
}

#' generate density plots for each element in a list of TrackingAll
#' 
#' iterates over a list of tracking data objects and generate density path plots
#' for each, adding a title with the group name and index
#' 
#' @param TrackingAll A list of tracking data objects (from RunPipeline)
#' @param groupName A character string for the group label to use in the plot titles
#' @return A list of ggplot objects for all density plots generated
generate_density_plots <- function(TrackingAll, groupName) {
  all_plots <- list()
  for (i in seq_along(TrackingAll)) {
    density_paths_plots_2 <- PlotDensityPaths_2(TrackingAll[[i]], points = c("Head"))
    if (!is.null(density_paths_plots_2)) {
      density_paths_plots_2 <- lapply(
        density_paths_plots_2,
        function(plot) plot + ggtitle(paste(groupName, i))
      )
      all_plots <- c(all_plots, density_paths_plots_2)
    }
  }
  all_plots
}